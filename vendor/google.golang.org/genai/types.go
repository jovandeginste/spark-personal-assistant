// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by the Google Gen AI SDK generator DO NOT EDIT.

package genai

import (
	"cloud.google.com/go/civil"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"strconv"
	"strings"
	"time"
)

// Outcome of the code execution.
type Outcome string

const (
	// Unspecified status. This value should not be used.
	OutcomeUnspecified Outcome = "OUTCOME_UNSPECIFIED"
	// Code execution completed successfully.
	OutcomeOK Outcome = "OUTCOME_OK"
	// Code execution finished but with a failure. `stderr` should contain the reason.
	OutcomeFailed Outcome = "OUTCOME_FAILED"
	// Code execution ran for too long, and was cancelled. There may or may not be a partial
	// output present.
	OutcomeDeadlineExceeded Outcome = "OUTCOME_DEADLINE_EXCEEDED"
)

// Programming language of the `code`.
type Language string

const (
	// Unspecified language. This value should not be used.
	LanguageUnspecified Language = "LANGUAGE_UNSPECIFIED"
	// Python >= 3.10, with numpy and simpy available.
	LanguagePython Language = "PYTHON"
)

// The type of the data.
type Type string

const (
	// Not specified, should not be used.
	TypeUnspecified Type = "TYPE_UNSPECIFIED"
	// OpenAPI string type
	TypeString Type = "STRING"
	// OpenAPI number type
	TypeNumber Type = "NUMBER"
	// OpenAPI integer type
	TypeInteger Type = "INTEGER"
	// OpenAPI boolean type
	TypeBoolean Type = "BOOLEAN"
	// OpenAPI array type
	TypeArray Type = "ARRAY"
	// OpenAPI object type
	TypeObject Type = "OBJECT"
)

// Harm category.
type HarmCategory string

const (
	// The harm category is unspecified.
	HarmCategoryUnspecified HarmCategory = "HARM_CATEGORY_UNSPECIFIED"
	// The harm category is hate speech.
	HarmCategoryHateSpeech HarmCategory = "HARM_CATEGORY_HATE_SPEECH"
	// The harm category is dangerous content.
	HarmCategoryDangerousContent HarmCategory = "HARM_CATEGORY_DANGEROUS_CONTENT"
	// The harm category is harassment.
	HarmCategoryHarassment HarmCategory = "HARM_CATEGORY_HARASSMENT"
	// The harm category is sexually explicit content.
	HarmCategorySexuallyExplicit HarmCategory = "HARM_CATEGORY_SEXUALLY_EXPLICIT"
	// The harm category is civic integrity.
	HarmCategoryCivicIntegrity HarmCategory = "HARM_CATEGORY_CIVIC_INTEGRITY"
)

// Specify if the threshold is used for probability or severity score. If not specified,
// the threshold is used for probability score.
type HarmBlockMethod string

const (
	// The harm block method is unspecified.
	HarmBlockMethodUnspecified HarmBlockMethod = "HARM_BLOCK_METHOD_UNSPECIFIED"
	// The harm block method uses both probability and severity scores.
	HarmBlockMethodSeverity HarmBlockMethod = "SEVERITY"
	// The harm block method uses the probability score.
	HarmBlockMethodProbability HarmBlockMethod = "PROBABILITY"
)

// The harm block threshold.
type HarmBlockThreshold string

const (
	// Unspecified harm block threshold.
	HarmBlockThresholdUnspecified HarmBlockThreshold = "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
	// Block low threshold and above (i.e. block more).
	HarmBlockThresholdBlockLowAndAbove HarmBlockThreshold = "BLOCK_LOW_AND_ABOVE"
	// Block medium threshold and above.
	HarmBlockThresholdBlockMediumAndAbove HarmBlockThreshold = "BLOCK_MEDIUM_AND_ABOVE"
	// Block only high threshold (i.e. block less).
	HarmBlockThresholdBlockOnlyHigh HarmBlockThreshold = "BLOCK_ONLY_HIGH"
	// Block none.
	HarmBlockThresholdBlockNone HarmBlockThreshold = "BLOCK_NONE"
	// Turn off the safety filter.
	HarmBlockThresholdOff HarmBlockThreshold = "OFF"
)

// The mode of the predictor to be used in dynamic retrieval.
type Mode string

const (
	// Always trigger retrieval.
	ModeUnspecified Mode = "MODE_UNSPECIFIED"
	// Run retrieval only when system decides it is necessary.
	ModeDynamic Mode = "MODE_DYNAMIC"
)

// The reason why the model stopped generating tokens.
// If empty, the model has not stopped generating the tokens.
type FinishReason string

const (
	// The finish reason is unspecified.
	FinishReasonUnspecified FinishReason = "FINISH_REASON_UNSPECIFIED"
	// Token generation reached a natural stopping point or a configured stop sequence.
	FinishReasonStop FinishReason = "STOP"
	// Token generation reached the configured maximum output tokens.
	FinishReasonMaxTokens FinishReason = "MAX_TOKENS"
	// Token generation stopped because the content potentially contains safety violations.
	// NOTE: When streaming, [content][] is empty if content filters blocks the output.
	FinishReasonSafety FinishReason = "SAFETY"
	// The token generation stopped because of potential recitation.
	FinishReasonRecitation FinishReason = "RECITATION"
	// The token generation stopped because of using an unsupported language.
	FinishReasonLanguage FinishReason = "LANGUAGE"
	// All other reasons that stopped the token generation.
	FinishReasonOther FinishReason = "OTHER"
	// Token generation stopped because the content contains forbidden terms.
	FinishReasonBlocklist FinishReason = "BLOCKLIST"
	// Token generation stopped for potentially containing prohibited content.
	FinishReasonProhibitedContent FinishReason = "PROHIBITED_CONTENT"
	// Token generation stopped because the content potentially contains Sensitive Personally
	// Identifiable Information (SPII).
	FinishReasonSPII FinishReason = "SPII"
	// The function call generated by the model is invalid.
	FinishReasonMalformedFunctionCall FinishReason = "MALFORMED_FUNCTION_CALL"
	// Token generation stopped because generated images have safety violations.
	FinishReasonImageSafety FinishReason = "IMAGE_SAFETY"
)

// Harm probability levels in the content.
type HarmProbability string

const (
	// Harm probability unspecified.
	HarmProbabilityUnspecified HarmProbability = "HARM_PROBABILITY_UNSPECIFIED"
	// Negligible level of harm.
	HarmProbabilityNegligible HarmProbability = "NEGLIGIBLE"
	// Low level of harm.
	HarmProbabilityLow HarmProbability = "LOW"
	// Medium level of harm.
	HarmProbabilityMedium HarmProbability = "MEDIUM"
	// High level of harm.
	HarmProbabilityHigh HarmProbability = "HIGH"
)

// Harm severity levels in the content.
type HarmSeverity string

const (
	// Harm severity unspecified.
	HarmSeverityUnspecified HarmSeverity = "HARM_SEVERITY_UNSPECIFIED"
	// Negligible level of harm severity.
	HarmSeverityNegligible HarmSeverity = "HARM_SEVERITY_NEGLIGIBLE"
	// Low level of harm severity.
	HarmSeverityLow HarmSeverity = "HARM_SEVERITY_LOW"
	// Medium level of harm severity.
	HarmSeverityMedium HarmSeverity = "HARM_SEVERITY_MEDIUM"
	// High level of harm severity.
	HarmSeverityHigh HarmSeverity = "HARM_SEVERITY_HIGH"
)

// Blocked reason.
type BlockedReason string

const (
	// Unspecified blocked reason.
	BlockedReasonUnspecified BlockedReason = "BLOCKED_REASON_UNSPECIFIED"
	// Candidates blocked due to safety.
	BlockedReasonSafety BlockedReason = "SAFETY"
	// Candidates blocked due to other reason.
	BlockedReasonOther BlockedReason = "OTHER"
	// Candidates blocked due to the terms which are included from the terminology blocklist.
	BlockedReasonBlocklist BlockedReason = "BLOCKLIST"
	// Candidates blocked due to prohibited content.
	BlockedReasonProhibitedContent BlockedReason = "PROHIBITED_CONTENT"
)

// Traffic type. This shows whether a request consumes Pay-As-You-Go or Provisioned
// Throughput quota.
type TrafficType string

const (
	// Unspecified request traffic type.
	TrafficTypeUnspecified TrafficType = "TRAFFIC_TYPE_UNSPECIFIED"
	// Type for Pay-As-You-Go traffic.
	TrafficTypeOnDemand TrafficType = "ON_DEMAND"
	// Type for Provisioned Throughput traffic.
	TrafficTypeProvisionedThroughput TrafficType = "PROVISIONED_THROUGHPUT"
)

// Server content modalities.
type Modality string

const (
	// The modality is unspecified.
	ModalityUnspecified Modality = "MODALITY_UNSPECIFIED"
	// Indicates the model should return text
	ModalityText Modality = "TEXT"
	// Indicates the model should return images.
	ModalityImage Modality = "IMAGE"
	// Indicates the model should return images.
	ModalityAudio Modality = "AUDIO"
)

// The media resolution to use.
type MediaResolution string

const (
	// Media resolution has not been set
	MediaResolutionUnspecified MediaResolution = "MEDIA_RESOLUTION_UNSPECIFIED"
	// Media resolution set to low (64 tokens).
	MediaResolutionLow MediaResolution = "MEDIA_RESOLUTION_LOW"
	// Media resolution set to medium (256 tokens).
	MediaResolutionMedium MediaResolution = "MEDIA_RESOLUTION_MEDIUM"
	// Media resolution set to high (zoomed reframing with 256 tokens).
	MediaResolutionHigh MediaResolution = "MEDIA_RESOLUTION_HIGH"
)

// Options for feature selection preference.
type FeatureSelectionPreference string

const (
	FeatureSelectionPreferenceUnspecified       FeatureSelectionPreference = "FEATURE_SELECTION_PREFERENCE_UNSPECIFIED"
	FeatureSelectionPreferencePrioritizeQuality FeatureSelectionPreference = "PRIORITIZE_QUALITY"
	FeatureSelectionPreferenceBalanced          FeatureSelectionPreference = "BALANCED"
	FeatureSelectionPreferencePrioritizeCost    FeatureSelectionPreference = "PRIORITIZE_COST"
)

// Config for the dynamic retrieval config mode.
type DynamicRetrievalConfigMode string

const (
	// Always trigger retrieval.
	DynamicRetrievalConfigModeUnspecified DynamicRetrievalConfigMode = "MODE_UNSPECIFIED"
	// Run retrieval only when system decides it is necessary.
	DynamicRetrievalConfigModeDynamic DynamicRetrievalConfigMode = "MODE_DYNAMIC"
)

// Config for the function calling config mode.
type FunctionCallingConfigMode string

const (
	// The function calling config mode is unspecified. Should not be used.
	FunctionCallingConfigModeUnspecified FunctionCallingConfigMode = "MODE_UNSPECIFIED"
	// Default model behavior, model decides to predict either function calls or natural
	// language response.
	FunctionCallingConfigModeAuto FunctionCallingConfigMode = "AUTO"
	// Model is constrained to always predicting function calls only. If "allowed_function_names"
	// are set, the predicted function calls will be limited to any one of "allowed_function_names",
	// else the predicted function calls will be any one of the provided "function_declarations".
	FunctionCallingConfigModeAny FunctionCallingConfigMode = "ANY"
	// Model will not predict any function calls. Model behavior is same as when not passing
	// any function declarations.
	FunctionCallingConfigModeNone FunctionCallingConfigMode = "NONE"
)

// Enum that controls the safety filter level for objectionable content.
type SafetyFilterLevel string

const (
	SafetyFilterLevelBlockLowAndAbove    SafetyFilterLevel = "BLOCK_LOW_AND_ABOVE"
	SafetyFilterLevelBlockMediumAndAbove SafetyFilterLevel = "BLOCK_MEDIUM_AND_ABOVE"
	SafetyFilterLevelBlockOnlyHigh       SafetyFilterLevel = "BLOCK_ONLY_HIGH"
	SafetyFilterLevelBlockNone           SafetyFilterLevel = "BLOCK_NONE"
)

// Enum that controls the generation of people.
type PersonGeneration string

const (
	PersonGenerationDontAllow  PersonGeneration = "DONT_ALLOW"
	PersonGenerationAllowAdult PersonGeneration = "ALLOW_ADULT"
	PersonGenerationAllowAll   PersonGeneration = "ALLOW_ALL"
)

// Enum that specifies the language of the text in the prompt.
type ImagePromptLanguage string

const (
	ImagePromptLanguageAuto ImagePromptLanguage = "auto"
	ImagePromptLanguageEn   ImagePromptLanguage = "en"
	ImagePromptLanguageJa   ImagePromptLanguage = "ja"
	ImagePromptLanguageKo   ImagePromptLanguage = "ko"
	ImagePromptLanguageHi   ImagePromptLanguage = "hi"
)

// Enum representing the mask mode of a mask reference image.
type MaskReferenceMode string

const (
	MaskReferenceModeMaskModeDefault      MaskReferenceMode = "MASK_MODE_DEFAULT"
	MaskReferenceModeMaskModeUserProvided MaskReferenceMode = "MASK_MODE_USER_PROVIDED"
	MaskReferenceModeMaskModeBackground   MaskReferenceMode = "MASK_MODE_BACKGROUND"
	MaskReferenceModeMaskModeForeground   MaskReferenceMode = "MASK_MODE_FOREGROUND"
	MaskReferenceModeMaskModeSemantic     MaskReferenceMode = "MASK_MODE_SEMANTIC"
)

// Enum representing the control type of a control reference image.
type ControlReferenceType string

const (
	ControlReferenceTypeDefault  ControlReferenceType = "CONTROL_TYPE_DEFAULT"
	ControlReferenceTypeCanny    ControlReferenceType = "CONTROL_TYPE_CANNY"
	ControlReferenceTypeScribble ControlReferenceType = "CONTROL_TYPE_SCRIBBLE"
	ControlReferenceTypeFaceMesh ControlReferenceType = "CONTROL_TYPE_FACE_MESH"
)

// Enum representing the subject type of a subject reference image.
type SubjectReferenceType string

const (
	SubjectReferenceTypeSubjectTypeDefault SubjectReferenceType = "SUBJECT_TYPE_DEFAULT"
	SubjectReferenceTypeSubjectTypePerson  SubjectReferenceType = "SUBJECT_TYPE_PERSON"
	SubjectReferenceTypeSubjectTypeAnimal  SubjectReferenceType = "SUBJECT_TYPE_ANIMAL"
	SubjectReferenceTypeSubjectTypeProduct SubjectReferenceType = "SUBJECT_TYPE_PRODUCT"
)

// Enum representing the Imagen 3 Edit mode.
type EditMode string

const (
	EditModeDefault           EditMode = "EDIT_MODE_DEFAULT"
	EditModeInpaintRemoval    EditMode = "EDIT_MODE_INPAINT_REMOVAL"
	EditModeInpaintInsertion  EditMode = "EDIT_MODE_INPAINT_INSERTION"
	EditModeOutpaint          EditMode = "EDIT_MODE_OUTPAINT"
	EditModeControlledEditing EditMode = "EDIT_MODE_CONTROLLED_EDITING"
	EditModeStyle             EditMode = "EDIT_MODE_STYLE"
	EditModeBgswap            EditMode = "EDIT_MODE_BGSWAP"
	EditModeProductImage      EditMode = "EDIT_MODE_PRODUCT_IMAGE"
)

// State for the lifecycle of a File.
type FileState string

const (
	FileStateUnspecified FileState = "STATE_UNSPECIFIED"
	FileStateProcessing  FileState = "PROCESSING"
	FileStateActive      FileState = "ACTIVE"
	FileStateFailed      FileState = "FAILED"
)

// Source of the File.
type FileSource string

const (
	FileSourceUnspecified FileSource = "SOURCE_UNSPECIFIED"
	FileSourceUploaded    FileSource = "UPLOADED"
	FileSourceGenerated   FileSource = "GENERATED"
)

// Server content modalities.
type MediaModality string

const (
	// The modality is unspecified.
	MediaModalityUnspecified MediaModality = "MODALITY_UNSPECIFIED"
	// Plain text.
	MediaModalityText MediaModality = "TEXT"
	// Images.
	MediaModalityImage MediaModality = "IMAGE"
	// Video.
	MediaModalityVideo MediaModality = "VIDEO"
	// Audio.
	MediaModalityAudio MediaModality = "AUDIO"
	// Document, e.g. PDF.
	MediaModalityDocument MediaModality = "DOCUMENT"
)

// Start of speech sensitivity.
type StartSensitivity string

const (
	// The default is START_SENSITIVITY_LOW.
	StartSensitivityUnspecified StartSensitivity = "START_SENSITIVITY_UNSPECIFIED"
	// Automatic detection will detect the start of speech more often.
	StartSensitivityHigh StartSensitivity = "START_SENSITIVITY_HIGH"
	// Automatic detection will detect the start of speech less often.
	StartSensitivityLow StartSensitivity = "START_SENSITIVITY_LOW"
)

// End of speech sensitivity.
type EndSensitivity string

const (
	// The default is END_SENSITIVITY_LOW.
	EndSensitivityUnspecified EndSensitivity = "END_SENSITIVITY_UNSPECIFIED"
	// Automatic detection ends speech more often.
	EndSensitivityHigh EndSensitivity = "END_SENSITIVITY_HIGH"
	// Automatic detection ends speech less often.
	EndSensitivityLow EndSensitivity = "END_SENSITIVITY_LOW"
)

// The different ways of handling user activity.
type ActivityHandling string

const (
	// If unspecified, the default behavior is `START_OF_ACTIVITY_INTERRUPTS`.
	ActivityHandlingUnspecified ActivityHandling = "ACTIVITY_HANDLING_UNSPECIFIED"
	// If true, start of activity will interrupt the model's response (also called "barge
	// in"). The model's current response will be cut-off in the moment of the interruption.
	// This is the default behavior.
	ActivityHandlingStartOfActivityInterrupts ActivityHandling = "START_OF_ACTIVITY_INTERRUPTS"
	// The model's response will not be interrupted.
	ActivityHandlingNoInterruption ActivityHandling = "NO_INTERRUPTION"
)

// Options about which input is included in the user's turn.
type TurnCoverage string

const (
	// If unspecified, the default behavior is `TURN_INCLUDES_ONLY_ACTIVITY`.
	TurnCoverageUnspecified TurnCoverage = "TURN_COVERAGE_UNSPECIFIED"
	// The users turn only includes activity since the last turn, excluding inactivity (e.g.
	// silence on the audio stream). This is the default behavior.
	TurnCoverageTurnIncludesOnlyActivity TurnCoverage = "TURN_INCLUDES_ONLY_ACTIVITY"
	// The users turn includes all realtime input since the last turn, including inactivity
	// (e.g. silence on the audio stream).
	TurnCoverageTurnIncludesAllInput TurnCoverage = "TURN_INCLUDES_ALL_INPUT"
)

// Metadata describes the input video content.
type VideoMetadata struct {
	// Optional. The end offset of the video.
	EndOffset time.Duration `json:"endOffset,omitempty"`
	// Optional. The start offset of the video.
	StartOffset time.Duration `json:"startOffset,omitempty"`
}

func (c *VideoMetadata) UnmarshalJSON(data []byte) error {
	type Alias VideoMetadata
	aux := &struct {
		EndOffset   string `json:"endOffset,omitempty"`
		StartOffset string `json:"startOffset,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.EndOffset != "" {
		d, err := time.ParseDuration(aux.EndOffset)
		if err != nil {
			return err
		}
		c.EndOffset = d
	}

	if aux.StartOffset != "" {
		d, err := time.ParseDuration(aux.StartOffset)
		if err != nil {
			return err
		}
		c.StartOffset = d
	}

	return nil
}

func (c *VideoMetadata) MarshalJSON() ([]byte, error) {
	type Alias VideoMetadata
	aux := &struct {
		EndOffset   string `json:"endOffset,omitempty"`
		StartOffset string `json:"startOffset,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if c.StartOffset != 0 {
		aux.StartOffset = fmt.Sprintf("%.0fs", c.StartOffset.Seconds())
	}
	if c.EndOffset != 0 {
		aux.EndOffset = fmt.Sprintf("%.0fs", c.EndOffset.Seconds())
		if aux.StartOffset == "" {
			aux.StartOffset = "0s"
		}
	}

	return json.Marshal(aux)
}

// Result of executing the [ExecutableCode]. Always follows a `part` containing the
// [ExecutableCode].
type CodeExecutionResult struct {
	// Required. Outcome of the code execution.
	Outcome Outcome `json:"outcome,omitempty"`
	// Optional. Contains stdout when code execution is successful, stderr or other description
	// otherwise.
	Output string `json:"output,omitempty"`
}

// Code generated by the model that is meant to be executed, and the result returned
// to the model. Generated when using the [FunctionDeclaration] tool and [FunctionCallingConfig]
// mode is set to [Mode.CODE].
type ExecutableCode struct {
	// Required. The code to be executed.
	Code string `json:"code,omitempty"`
	// Required. Programming language of the `code`.
	Language Language `json:"language,omitempty"`
}

// URI based data.
type FileData struct {
	// Required. URI.
	FileURI string `json:"fileUri,omitempty"`
	// Required. The IANA standard MIME type of the source data.
	MIMEType string `json:"mimeType,omitempty"`
}

// A function call.
type FunctionCall struct {
	// The unique ID of the function call. If populated, the client to execute the
	// `function_call` and return the response with the matching `id`.
	ID string `json:"id,omitempty"`
	// Optional. Required. The function parameters and values in JSON object format. See
	// [FunctionDeclaration.parameters] for parameter details.
	Args map[string]any `json:"args,omitempty"`
	// Required. The name of the function to call. Matches [FunctionDeclaration.Name].
	Name string `json:"name,omitempty"`
}

// A function response.
type FunctionResponse struct {
	// The ID of the function call this response is for. Populated by the client
	// to match the corresponding function call `id`.
	ID string `json:"id,omitempty"`
	// Required. The name of the function to call. Matches [FunctionDeclaration.name] and
	// [FunctionCall.name].
	Name string `json:"name,omitempty"`
	// Required. The function response in JSON object format. Use "output" key to specify
	// function output and "error" key to specify error details (if any). If "output" and
	// "error" keys are not specified, then whole "response" is treated as function output.
	Response map[string]any `json:"response,omitempty"`
}

// Content blob.
type Blob struct {
	// Required. Raw bytes.
	Data []byte `json:"data,omitempty"`
	// Required. The IANA standard MIME type of the source data.
	MIMEType string `json:"mimeType,omitempty"`
}

// A datatype containing media content.
// Exactly one field within a Part should be set, representing the specific type
// of content being conveyed. Using multiple fields within the same `Part`
// instance is considered invalid.
type Part struct {
	// Metadata for a given video.
	VideoMetadata *VideoMetadata `json:"videoMetadata,omitempty"`
	// Indicates if the part is thought from the model.
	Thought bool `json:"thought,omitempty"`
	// Optional. Result of executing the [ExecutableCode].
	CodeExecutionResult *CodeExecutionResult `json:"codeExecutionResult,omitempty"`
	// Optional. Code generated by the model that is meant to be executed.
	ExecutableCode *ExecutableCode `json:"executableCode,omitempty"`
	// Optional. URI based data.
	FileData *FileData `json:"fileData,omitempty"`
	// Optional. A predicted [FunctionCall] returned from the model that contains a string
	// representing the [FunctionDeclaration.Name] with the parameters and their values.
	FunctionCall *FunctionCall `json:"functionCall,omitempty"`
	// Optional. The result output of a [FunctionCall] that contains a string representing
	// the [FunctionDeclaration.Name] and a structured JSON object containing any output
	// from the function call. It is used as context to the model.
	FunctionResponse *FunctionResponse `json:"functionResponse,omitempty"`
	// Optional. Inlined bytes data.
	InlineData *Blob `json:"inlineData,omitempty"`
	// Optional. Text part (can be code).
	Text string `json:"text,omitempty"`
}

// NewPartFromURI builds a Part from a given file URI and mime type.
func NewPartFromURI(fileURI, mimeType string) *Part {
	return &Part{
		FileData: &FileData{
			FileURI:  fileURI,
			MIMEType: mimeType,
		},
	}
}

// NewPartFromText builds a Part from a given text.
func NewPartFromText(text string) *Part {
	return &Part{
		Text: text,
	}
}

// NewPartFromBytes builds a Part from a given byte array and mime type.
func NewPartFromBytes(data []byte, mimeType string) *Part {
	return &Part{
		InlineData: &Blob{
			Data:     data,
			MIMEType: mimeType,
		},
	}
}

// NewPartFromFunctionCall builds a [FunctionCall] Part from the given function name and args.
func NewPartFromFunctionCall(name string, args map[string]any) *Part {
	return &Part{
		FunctionCall: &FunctionCall{
			Name: name,
			Args: args,
		},
	}
}

// NewPartFromFunctionResponse builds a [FunctionResponse] Part from the given function name and response.
func NewPartFromFunctionResponse(name string, response map[string]any) *Part {
	return &Part{
		FunctionResponse: &FunctionResponse{
			Name:     name,
			Response: response,
		},
	}
}

// NewPartFromExecutableCode builds a [ExecutableCode] Part from a single piece of source code in the given [Language].
func NewPartFromExecutableCode(code string, language Language) *Part {
	return &Part{
		ExecutableCode: &ExecutableCode{
			Code:     code,
			Language: language,
		},
	}
}

// NewPartFromCodeExecutionResult builds a [CodeExecutionResult] Part from the given [Outcome] and std output.
func NewPartFromCodeExecutionResult(outcome Outcome, output string) *Part {
	return &Part{
		CodeExecutionResult: &CodeExecutionResult{
			Outcome: outcome,
			Output:  output,
		},
	}
}

// Contains the multi-part content of a message.
type Content struct {
	// List of parts that constitute a single message. Each part may have
	// a different IANA MIME type.
	Parts []*Part `json:"parts,omitempty"`
	// Optional. The producer of the content. Must be either 'user' or
	// 'model'. Useful to set for multi-turn conversations, otherwise can be
	// empty. If role is not specified, SDK will determine the role.
	Role string `json:"role,omitempty"`
}

type Role string

const (
	RoleUser  = "user"
	RoleModel = "model"
)

func roleString(role Role) string {
	if role == "" {
		return "user"
	}
	return string(role)
}

// NewContentFromParts builds a Content from a list of parts and a [Role].
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromParts(parts []*Part, role Role) *Content {
	return &Content{
		Parts: parts,
		Role:  roleString(role),
	}
}

// NewContentFromText builds a Content from a text string.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromText(text string, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromText(text),
		},
		Role: roleString(role),
	}
}

// NewContentFromBytes builds a Content from a byte slice and mime type.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromBytes(data []byte, mimeType string, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromBytes(data, mimeType),
		},
		Role: roleString(role),
	}
}

// NewContentFromURI builds a Content from a file URI and mime type.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromURI(fileURI, mimeType string, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromURI(fileURI, mimeType),
		},
		Role: roleString(role),
	}
}

// NewContentFromFunctionCall builds a Content from a single [FunctionCall] given the function name and args.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromFunctionCall(name string, args map[string]any, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromFunctionCall(name, args),
		},
		Role: roleString(role),
	}
}

// NewContentFromFunctionResponse builds a Content from a single [FunctionResponse] given the function name and response.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromFunctionResponse(name string, response map[string]any, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromFunctionResponse(name, response),
		},
		Role: roleString(role),
	}
}

// NewContentFromExecutableCode builds a Content from a single piece of source code in the given [Language].
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromExecutableCode(code string, language Language, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromExecutableCode(code, language),
		},
		Role: roleString(role),
	}
}

// NewContentFromCodeExecutionResult builds a Content from a given [Outcome] and std output of the code execution.
// If role is the empty string, it defaults to [RoleUser].
func NewContentFromCodeExecutionResult(outcome Outcome, output string, role Role) *Content {
	return &Content{
		Parts: []*Part{
			NewPartFromCodeExecutionResult(outcome, output),
		},
		Role: roleString(role),
	}
}

// HTTP options to be used in each of the requests.
type HTTPOptions struct {
	// BaseURL specifies the base URL for the API endpoint. If empty, defaults to "https://generativelanguage.googleapis.com/"
	// for the Gemini API backend, and location-specific Vertex AI endpoint (e.g., "https://us-central1-aiplatform.googleapis.com/
	BaseURL string `json:"baseUrl,omitempty"`
	// APIVersion specifies the version of the API to use. If empty, defaults to "v1beta"
	// for Gemini API and "v1beta1" for Vertex AI.
	APIVersion string `json:"apiVersion,omitempty"`
	// Additional HTTP headers to be sent with the request.
	Headers http.Header `json:"headers,omitempty"`
}

// Schema that defines the format of input and output data.
// Represents a select subset of an OpenAPI 3.0 schema object.
// You can find more details and examples at https://spec.openapis.org/oas/v3.0.3.html#schema-object
type Schema struct {
	// Optional. Example of the object. Will only populated when the object is the root.
	Example any `json:"example,omitempty"`
	// Optional. Pattern of the Type.STRING to restrict a string to a regular expression.
	Pattern string `json:"pattern,omitempty"`
	// Optional. Default value of the data.
	Default any `json:"default,omitempty"`
	// Optional. Maximum length of the Type.STRING
	MaxLength *int64 `json:"maxLength,omitempty"`
	// Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING
	MinLength *int64 `json:"minLength,omitempty"`
	// Optional. Minimum number of the properties for Type.OBJECT.
	MinProperties *int64 `json:"minProperties,omitempty"`
	// Optional. Maximum number of the properties for Type.OBJECT.
	MaxProperties *int64 `json:"maxProperties,omitempty"`
	// Optional. The value should be validated against any (one or more) of the subschemas
	// in the list.
	AnyOf []*Schema `json:"anyOf,omitempty"`
	// Optional. The description of the data.
	Description string `json:"description,omitempty"`
	// Optional. Possible values of the element of primitive type with enum format. Examples:
	// 1. We can define direction as : {type:STRING, format:enum, enum:["EAST", NORTH",
	// "SOUTH", "WEST"]} 2. We can define apartment number as : {type:INTEGER, format:enum,
	// enum:["101", "201", "301"]}
	Enum []string `json:"enum,omitempty"`
	// Optional. The format of the data. Supported formats: for NUMBER type: "float", "double"
	// for INTEGER type: "int32", "int64" for STRING type: "email", "byte", etc
	Format string `json:"format,omitempty"`
	// Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY.
	Items *Schema `json:"items,omitempty"`
	// Optional. Maximum number of the elements for Type.ARRAY.
	MaxItems *int64 `json:"maxItems,omitempty"`
	// Optional. Maximum value of the Type.INTEGER and Type.NUMBER
	Maximum *float64 `json:"maximum,omitempty"`
	// Optional. Minimum number of the elements for Type.ARRAY.
	MinItems *int64 `json:"minItems,omitempty"`
	// Optional. Minimum value of the Type.INTEGER and Type.NUMBER.
	Minimum *float64 `json:"minimum,omitempty"`
	// Optional. Indicates if the value may be null.
	Nullable *bool `json:"nullable,omitempty"`
	// Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.
	Properties map[string]*Schema `json:"properties,omitempty"`
	// Optional. The order of the properties. Not a standard field in open API spec. Only
	// used to support the order of the properties.
	PropertyOrdering []string `json:"propertyOrdering,omitempty"`
	// Optional. Required properties of Type.OBJECT.
	Required []string `json:"required,omitempty"`
	// Optional. The title of the Schema.
	Title string `json:"title,omitempty"`
	// Optional. The type of the data.
	Type Type `json:"type,omitempty"`
}

func (s *Schema) UnmarshalJSON(data []byte) error {
	type Alias Schema
	aux := &struct {
		MaxLength     string `json:"maxLength,omitempty"`
		MinLength     string `json:"minLength,omitempty"`
		MinProperties string `json:"minProperties,omitempty"`
		MaxProperties string `json:"maxProperties,omitempty"`
		MaxItems      string `json:"maxItems,omitempty"`
		MinItems      string `json:"minItems,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(s),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.MaxLength != "" {
		maxLength, err := strconv.ParseInt(aux.MaxLength, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MaxLength: %w", err)
		}
		s.MaxLength = &maxLength
	}

	if aux.MinLength != "" {
		minLength, err := strconv.ParseInt(aux.MinLength, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MinLength: %w", err)
		}
		s.MinLength = &minLength
	}

	if aux.MinProperties != "" {
		minProperties, err := strconv.ParseInt(aux.MinProperties, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MinProperties: %w", err)
		}
		s.MinProperties = &minProperties
	}

	if aux.MaxProperties != "" {
		maxProperties, err := strconv.ParseInt(aux.MaxProperties, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MaxProperties: %w", err)
		}
		s.MaxProperties = &maxProperties
	}

	if aux.MaxItems != "" {
		maxItems, err := strconv.ParseInt(aux.MaxItems, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MaxItems: %w", err)
		}
		s.MaxItems = &maxItems
	}

	if aux.MinItems != "" {
		minItems, err := strconv.ParseInt(aux.MinItems, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing MinItems: %w", err)
		}
		s.MinItems = &minItems
	}

	return nil
}

func (s *Schema) MarshalJSON() ([]byte, error) {
	type Alias Schema
	aux := struct {
		MaxLength     string `json:"maxLength,omitempty"`
		MinLength     string `json:"minLength,omitempty"`
		MinProperties string `json:"minProperties,omitempty"`
		MaxProperties string `json:"maxProperties,omitempty"`
		MaxItems      string `json:"maxItems,omitempty"`
		MinItems      string `json:"minItems,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(s),
	}

	if s.MaxLength != nil {
		aux.MaxLength = strconv.FormatInt(*s.MaxLength, 10)
	}
	if s.MinLength != nil {
		aux.MinLength = strconv.FormatInt(*s.MinLength, 10)
	}
	if s.MinProperties != nil {
		aux.MinProperties = strconv.FormatInt(*s.MinProperties, 10)
	}
	if s.MaxProperties != nil {
		aux.MaxProperties = strconv.FormatInt(*s.MaxProperties, 10)
	}
	if s.MaxItems != nil {
		aux.MaxItems = strconv.FormatInt(*s.MaxItems, 10)
	}
	if s.MinItems != nil {
		aux.MinItems = strconv.FormatInt(*s.MinItems, 10)
	}
	return json.Marshal(aux)
}

// Config for model selection.
type ModelSelectionConfig struct {
	// Options for feature selection preference.
	FeatureSelectionPreference FeatureSelectionPreference `json:"featureSelectionPreference,omitempty"`
}

// Safety settings.
type SafetySetting struct {
	// Determines if the harm block method uses probability or probability
	// and severity scores.
	Method HarmBlockMethod `json:"method,omitempty"`
	// Required. Harm category.
	Category HarmCategory `json:"category,omitempty"`
	// Required. The harm block threshold.
	Threshold HarmBlockThreshold `json:"threshold,omitempty"`
}

// Defines a function that the model can generate JSON inputs for.
// The inputs are based on `OpenAPI 3.0 specifications
// <https://spec.openapis.org/oas/v3.0.3>`_.
type FunctionDeclaration struct {
	// Describes the output from the function in the OpenAPI JSON Schema
	// Object format.
	Response *Schema `json:"response,omitempty"`
	// Optional. Description and purpose of the function. Model uses it to decide how and
	// whether to call the function.
	Description string `json:"description,omitempty"`
	// Required. The name of the function to call. Must start with a letter or an underscore.
	// Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length
	// of 64.
	Name string `json:"name,omitempty"`
	// Optional. Describes the parameters to this function in JSON Schema Object format.
	// Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter.
	// Parameter names are case sensitive. Schema Value: the Schema defining the type used
	// for the parameter. For function with no parameters, this can be left unset. Parameter
	// names must start with a letter or an underscore and must only contain chars a-z,
	// A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and
	// 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type:
	// INTEGER required: - param1
	Parameters *Schema `json:"parameters,omitempty"`
}

// Tool to support Google Search in Model. Powered by Google.
type GoogleSearch struct {
}

// Describes the options to customize dynamic retrieval.
type DynamicRetrievalConfig struct {
	// The mode of the predictor to be used in dynamic retrieval.
	Mode DynamicRetrievalConfigMode `json:"mode,omitempty"`
	// Optional. The threshold to be used in dynamic retrieval. If empty, a system default
	// value is used.
	DynamicThreshold *float32 `json:"dynamicThreshold,omitempty"`
}

// Tool to retrieve public web data for grounding, powered by Google.
type GoogleSearchRetrieval struct {
	// Specifies the dynamic retrieval configuration for the given source.
	DynamicRetrievalConfig *DynamicRetrievalConfig `json:"dynamicRetrievalConfig,omitempty"`
}

// Retrieve from Vertex AI Search datastore or engine for grounding. datastore and engine
// are mutually exclusive. See https://cloud.google.com/products/agent-builder
type VertexAISearch struct {
	// Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
	Datastore string `json:"datastore,omitempty"`
	// Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`
	Engine string `json:"engine,omitempty"`
}

// The definition of the RAG resource.
type VertexRAGStoreRAGResource struct {
	// Optional. RAGCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`
	RAGCorpus string `json:"ragCorpus,omitempty"`
	// Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus
	// field.
	RAGFileIDs []string `json:"ragFileIds,omitempty"`
}

// Config for filters.
type RAGRetrievalConfigFilter struct {
	// Optional. String for metadata filtering.
	MetadataFilter string `json:"metadataFilter,omitempty"`
	// Optional. Only returns contexts with vector distance smaller than the threshold.
	VectorDistanceThreshold *float64 `json:"vectorDistanceThreshold,omitempty"`
	// Optional. Only returns contexts with vector similarity larger than the threshold.
	VectorSimilarityThreshold *float64 `json:"vectorSimilarityThreshold,omitempty"`
}

// Config for Hybrid Search.
type RAGRetrievalConfigHybridSearch struct {
	// Optional. Alpha value controls the weight between dense and sparse vector search
	// results. The range is [0, 1], while 0 means sparse vector search only and 1 means
	// dense vector search only. The default value is 0.5 which balances sparse and dense
	// vector search equally.
	Alpha *float32 `json:"alpha,omitempty"`
}

// Config for LlmRanker.
type RAGRetrievalConfigRankingLlmRanker struct {
	// Optional. The model name used for ranking. Format: `gemini-1.5-pro`
	ModelName string `json:"modelName,omitempty"`
}

// Config for Rank Service.
type RAGRetrievalConfigRankingRankService struct {
	// Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`
	ModelName string `json:"modelName,omitempty"`
}

// Config for ranking and reranking.
type RAGRetrievalConfigRanking struct {
	// Optional. Config for LlmRanker.
	LlmRanker *RAGRetrievalConfigRankingLlmRanker `json:"llmRanker,omitempty"`
	// Optional. Config for Rank Service.
	RankService *RAGRetrievalConfigRankingRankService `json:"rankService,omitempty"`
}

// Specifies the context retrieval config.
type RAGRetrievalConfig struct {
	// Optional. Config for filters.
	Filter *RAGRetrievalConfigFilter `json:"filter,omitempty"`
	// Optional. Config for Hybrid Search.
	HybridSearch *RAGRetrievalConfigHybridSearch `json:"hybridSearch,omitempty"`
	// Optional. Config for ranking and reranking.
	Ranking *RAGRetrievalConfigRanking `json:"ranking,omitempty"`
	// Optional. The number of contexts to retrieve.
	TopK *int32 `json:"topK,omitempty"`
}

// Retrieve from Vertex RAG Store for grounding. You can find API default values and
// more details at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-api-v1#parameters-list
type VertexRAGStore struct {
	// Optional. Deprecated. Please use rag_resources instead.
	RAGCorpora []string `json:"ragCorpora,omitempty"`
	// Optional. The representation of the RAG source. It can be used to specify corpus
	// only or ragfiles. Currently only support one corpus or multiple files from one corpus.
	// In the future we may open up multiple corpora support.
	RAGResources []*VertexRAGStoreRAGResource `json:"ragResources,omitempty"`
	// Optional. The retrieval config for the RAG query.
	RAGRetrievalConfig *RAGRetrievalConfig `json:"ragRetrievalConfig,omitempty"`
	// Optional. Number of top k results to return from the selected corpora.
	SimilarityTopK *int32 `json:"similarityTopK,omitempty"`
	// Optional. Only return results with vector distance smaller than the threshold.
	VectorDistanceThreshold *float64 `json:"vectorDistanceThreshold,omitempty"`
}

// Defines a retrieval tool that model can call to access external knowledge.
type Retrieval struct {
	// Optional. Deprecated. This option is no longer supported.
	DisableAttribution bool `json:"disableAttribution,omitempty"`
	// Set to use data source powered by Vertex AI Search.
	VertexAISearch *VertexAISearch `json:"vertexAiSearch,omitempty"`
	// Set to use data source powered by Vertex RAG store. User data is uploaded via the
	// VertexRAGDataService.
	VertexRAGStore *VertexRAGStore `json:"vertexRagStore,omitempty"`
}

// Tool that executes code generated by the model, and automatically returns the result
// to the model. See also [ExecutableCode]and [CodeExecutionResult] which are input
// and output to this tool.
type ToolCodeExecution struct {
}

// Tool details of a tool that the model may use to generate a response.
type Tool struct {
	// List of function declarations that the tool supports.
	FunctionDeclarations []*FunctionDeclaration `json:"functionDeclarations,omitempty"`
	// Optional. Retrieval tool type. System will always execute the provided retrieval
	// tool(s) to get external knowledge to answer the prompt. Retrieval results are presented
	// to the model for generation.
	Retrieval *Retrieval `json:"retrieval,omitempty"`
	// Optional. Google Search tool type. Specialized retrieval tool
	// that is powered by Google Search.
	GoogleSearch *GoogleSearch `json:"googleSearch,omitempty"`
	// Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered
	// by Google search.
	GoogleSearchRetrieval *GoogleSearchRetrieval `json:"googleSearchRetrieval,omitempty"`
	// Optional. CodeExecution tool type. Enables the model to execute code as part of generation.
	// This field is only used by the Gemini Developer API services.
	CodeExecution *ToolCodeExecution `json:"codeExecution,omitempty"`
}

// Function calling config.
type FunctionCallingConfig struct {
	// Optional. Function calling mode.
	Mode FunctionCallingConfigMode `json:"mode,omitempty"`
	// Optional. Function names to call. Only set when the Mode is ANY. Function names should
	// match [FunctionDeclaration.Name]. With mode set to ANY, model will predict a function
	// call from the set of function names provided.
	AllowedFunctionNames []string `json:"allowedFunctionNames,omitempty"`
}

// Tool config.
// This config is shared for all tools provided in the request.
type ToolConfig struct {
	// Optional. Function calling config.
	FunctionCallingConfig *FunctionCallingConfig `json:"functionCallingConfig,omitempty"`
}

// The configuration for the prebuilt speaker to use.
type PrebuiltVoiceConfig struct {
	// The name of the prebuilt voice to use.
	VoiceName string `json:"voiceName,omitempty"`
}

// The configuration for the voice to use.
type VoiceConfig struct {
	// The configuration for the speaker to use.
	PrebuiltVoiceConfig *PrebuiltVoiceConfig `json:"prebuiltVoiceConfig,omitempty"`
}

// The speech generation configuration.
type SpeechConfig struct {
	// The configuration for the speaker to use.
	VoiceConfig *VoiceConfig `json:"voiceConfig,omitempty"`
	// Language code (ISO 639. e.g. en-US) for the speech synthesization.
	// Only available for Live API.
	LanguageCode string `json:"languageCode,omitempty"`
}

// The thinking features configuration.
type ThinkingConfig struct {
	// Indicates whether to include thoughts in the response. If true, thoughts are returned
	// only if the model supports thought and thoughts are available.
	IncludeThoughts bool `json:"includeThoughts,omitempty"`
	// Indicates the thinking budget in tokens.
	ThinkingBudget *int32 `json:"thinkingBudget,omitempty"`
}

// When automated routing is specified, the routing will be determined by the pretrained
// routing model and customer provided model routing preference.
type GenerationConfigRoutingConfigAutoRoutingMode struct {
	// The model routing preference.
	ModelRoutingPreference string `json:"modelRoutingPreference,omitempty"`
}

// When manual routing is set, the specified model will be used directly.
type GenerationConfigRoutingConfigManualRoutingMode struct {
	// The model name to use. Only the public LLM models are accepted. e.g. 'gemini-1.5-pro-001'.
	ModelName string `json:"modelName,omitempty"`
}

// The configuration for routing the request to a specific model.
type GenerationConfigRoutingConfig struct {
	// Automated routing.
	AutoMode *GenerationConfigRoutingConfigAutoRoutingMode `json:"autoMode,omitempty"`
	// Manual routing.
	ManualMode *GenerationConfigRoutingConfigManualRoutingMode `json:"manualMode,omitempty"`
}

// Optional model configuration parameters.
// For more information, see `Content generation parameters
// <https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters>`_.
type GenerateContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Instructions for the model to steer it toward better performance.
	// For example, "Answer as concisely as possible" or "Don't use technical
	// terms in your response".
	SystemInstruction *Content `json:"systemInstruction,omitempty"`
	// Value that controls the degree of randomness in token selection.
	// Lower temperatures are good for prompts that require a less open-ended or
	// creative response, while higher temperatures can lead to more diverse or
	// creative results.
	Temperature *float32 `json:"temperature,omitempty"`
	// Tokens are selected from the most to least probable until the sum
	// of their probabilities equals this value. Use a lower value for less
	// random responses and a higher value for more random responses.
	TopP *float32 `json:"topP,omitempty"`
	// For each token selection step, the ``top_k`` tokens with the
	// highest probabilities are sampled. Then tokens are further filtered based
	// on ``top_p`` with the final token selected using temperature sampling. Use
	// a lower number for less random responses and a higher number for more
	// random responses.
	TopK *float32 `json:"topK,omitempty"`
	// Number of response variations to return.
	// If empty, the system will choose a default value (currently 1).
	CandidateCount int32 `json:"candidateCount,omitempty"`
	// Maximum number of tokens that can be generated in the response.
	// If empty, API will use a default value. The default value varies by model.
	MaxOutputTokens int32 `json:"maxOutputTokens,omitempty"`
	// List of strings that tells the model to stop generating text if one
	// of the strings is encountered in the response.
	StopSequences []string `json:"stopSequences,omitempty"`
	// Whether to return the log probabilities of the tokens that were
	// chosen by the model at each step.
	ResponseLogprobs bool `json:"responseLogprobs,omitempty"`
	// Number of top candidate tokens to return the log probabilities for
	// at each generation step.
	Logprobs *int32 `json:"logprobs,omitempty"`
	// Positive values penalize tokens that already appear in the
	// generated text, increasing the probability of generating more diverse
	// content.
	PresencePenalty *float32 `json:"presencePenalty,omitempty"`
	// Positive values penalize tokens that repeatedly appear in the
	// generated text, increasing the probability of generating more diverse
	// content.
	FrequencyPenalty *float32 `json:"frequencyPenalty,omitempty"`
	// When ``seed`` is fixed to a specific number, the model makes a best
	// effort to provide the same response for repeated requests. By default, a
	// random number is used.
	Seed *int32 `json:"seed,omitempty"`
	// Output response media type of the generated candidate text.
	ResponseMIMEType string `json:"responseMimeType,omitempty"`
	// Schema that the generated candidate text must adhere to.
	ResponseSchema *Schema `json:"responseSchema,omitempty"`
	// Configuration for model router requests.
	RoutingConfig *GenerationConfigRoutingConfig `json:"routingConfig,omitempty"`
	// Configuration for model selection.
	ModelSelectionConfig *ModelSelectionConfig `json:"modelSelectionConfig,omitempty"`
	// Safety settings in the request to block unsafe content in the
	// response.
	SafetySettings []*SafetySetting `json:"safetySettings,omitempty"`
	// Code that enables the system to interact with external systems to
	// perform an action outside of the knowledge and scope of the model.
	Tools []*Tool `json:"tools,omitempty"`
	// Associates model output to a specific function call.
	ToolConfig *ToolConfig `json:"toolConfig,omitempty"`
	// Labels with user-defined metadata to break down billed charges.
	Labels map[string]string `json:"labels,omitempty"`
	// Resource name of a context cache that can be used in subsequent
	// requests.
	CachedContent string `json:"cachedContent,omitempty"`
	// The requested modalities of the response. Represents the set of
	// modalities that the model can return.
	ResponseModalities []string `json:"responseModalities,omitempty"`
	// If specified, the media resolution specified will be used.
	MediaResolution MediaResolution `json:"mediaResolution,omitempty"`
	// The speech generation configuration.
	SpeechConfig *SpeechConfig `json:"speechConfig,omitempty"`
	// If enabled, audio timestamp will be included in the request to the
	// model.
	AudioTimestamp bool `json:"audioTimestamp,omitempty"`
	// The thinking features configuration.
	ThinkingConfig *ThinkingConfig `json:"thinkingConfig,omitempty"`
}

// Source attributions for content.
type Citation struct {
	// Output only. End index into the content.
	EndIndex int32 `json:"endIndex,omitempty"`
	// Output only. License of the attribution.
	License string `json:"license,omitempty"`
	// Output only. Publication date of the attribution.
	PublicationDate civil.Date `json:"publicationDate,omitempty"`
	// Output only. Start index into the content.
	StartIndex int32 `json:"startIndex,omitempty"`
	// Output only. Title of the attribution.
	Title string `json:"title,omitempty"`
	// Output only. URL reference of the attribution.
	URI string `json:"uri,omitempty"`
}

// UnmarshalJSON custom unmarshalling to handle PublicationDate as a map containing year, month, and day.
func (c *Citation) UnmarshalJSON(data []byte) error {
	type Alias Citation
	aux := &struct {
		PublicationDate map[string]int `json:"publicationDate"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.PublicationDate != nil {
		if _, ok := aux.PublicationDate["year"]; !ok {
			return fmt.Errorf("key %q not found", "year")
		}
		c.PublicationDate = civil.Date{Year: aux.PublicationDate["year"]}
		if month, ok := aux.PublicationDate["month"]; ok {
			c.PublicationDate.Month = time.Month(month)
		}
		if day, ok := aux.PublicationDate["day"]; ok {
			c.PublicationDate.Day = day
		}
	}

	return nil
}

func (c *Citation) MarshalJSON() ([]byte, error) {
	type Alias Citation
	aux := &struct {
		PublicationDate map[string]int `json:"publicationDate,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.PublicationDate.IsZero() {
		aux.PublicationDate = make(map[string]int)
		aux.PublicationDate["year"] = c.PublicationDate.Year
		aux.PublicationDate["month"] = int(c.PublicationDate.Month)
		aux.PublicationDate["day"] = c.PublicationDate.Day
	}

	return json.Marshal(aux)
}

// Citation information when the model quotes another source.
type CitationMetadata struct {
	// Contains citation information when the model directly quotes, at
	// length, from another source. Can include traditional websites and code
	// repositories.
	Citations []*Citation `json:"citations,omitempty"`
}

// Chunk from context retrieved by the retrieval tools.
type GroundingChunkRetrievedContext struct {
	// Text of the attribution.
	Text string `json:"text,omitempty"`
	// Title of the attribution.
	Title string `json:"title,omitempty"`
	// URI reference of the attribution.
	URI string `json:"uri,omitempty"`
}

// Chunk from the web.
type GroundingChunkWeb struct {
	// Domain of the (original) URI.
	Domain string `json:"domain,omitempty"`
	// Title of the chunk.
	Title string `json:"title,omitempty"`
	// URI reference of the chunk.
	URI string `json:"uri,omitempty"`
}

// Grounding chunk.
type GroundingChunk struct {
	// Grounding chunk from context retrieved by the retrieval tools.
	RetrievedContext *GroundingChunkRetrievedContext `json:"retrievedContext,omitempty"`
	// Grounding chunk from the web.
	Web *GroundingChunkWeb `json:"web,omitempty"`
}

// Segment of the content.
type Segment struct {
	// Output only. End index in the given Part, measured in bytes. Offset from the start
	// of the Part, exclusive, starting at zero.
	EndIndex int32 `json:"endIndex,omitempty"`
	// Output only. The index of a Part object within its parent Content object.
	PartIndex int32 `json:"partIndex,omitempty"`
	// Output only. Start index in the given Part, measured in bytes. Offset from the start
	// of the Part, inclusive, starting at zero.
	StartIndex int32 `json:"startIndex,omitempty"`
	// Output only. The text corresponding to the segment from the response.
	Text string `json:"text,omitempty"`
}

// Grounding support.
type GroundingSupport struct {
	// Confidence score of the support references. Ranges from 0 to 1. 1 is the most confident.
	// This list must have the same size as the grounding_chunk_indices.
	ConfidenceScores []float32 `json:"confidenceScores,omitempty"`
	// A list of indices (into 'grounding_chunk') specifying the citations associated with
	// the claim. For instance [1,3,4] means that grounding_chunk[1], grounding_chunk[3],
	// grounding_chunk[4] are the retrieved content attributed to the claim.
	GroundingChunkIndices []int32 `json:"groundingChunkIndices,omitempty"`
	// Segment of the content this support belongs to.
	Segment *Segment `json:"segment,omitempty"`
}

// Metadata related to retrieval in the grounding flow.
type RetrievalMetadata struct {
	// Optional. Score indicating how likely information from Google Search could help answer
	// the prompt. The score is in the range `[0, 1]`, where 0 is the least likely and 1
	// is the most likely. This score is only populated when Google Search grounding and
	// dynamic retrieval is enabled. It will be compared to the threshold to determine whether
	// to trigger Google Search.
	GoogleSearchDynamicRetrievalScore float32 `json:"googleSearchDynamicRetrievalScore,omitempty"`
}

// Google search entry point.
type SearchEntryPoint struct {
	// Optional. Web content snippet that can be embedded in a web page or an app webview.
	RenderedContent string `json:"renderedContent,omitempty"`
	// Optional. Base64 encoded JSON representing array of tuple.
	SDKBlob []byte `json:"sdkBlob,omitempty"`
}

// Metadata returned to client when grounding is enabled.
type GroundingMetadata struct {
	// List of supporting references retrieved from specified grounding source.
	GroundingChunks []*GroundingChunk `json:"groundingChunks,omitempty"`
	// Optional. List of grounding support.
	GroundingSupports []*GroundingSupport `json:"groundingSupports,omitempty"`
	// Optional. Output only. Retrieval metadata.
	RetrievalMetadata *RetrievalMetadata `json:"retrievalMetadata,omitempty"`
	// Optional. Queries executed by the retrieval tools.
	RetrievalQueries []string `json:"retrievalQueries,omitempty"`
	// Optional. Google search entry for the following-up web searches.
	SearchEntryPoint *SearchEntryPoint `json:"searchEntryPoint,omitempty"`
	// Optional. Web search queries for the following-up web search.
	WebSearchQueries []string `json:"webSearchQueries,omitempty"`
}

// Candidate for the logprobs token and score.
type LogprobsResultCandidate struct {
	// The candidate's log probability.
	LogProbability float32 `json:"logProbability,omitempty"`
	// The candidate's token string value.
	Token string `json:"token,omitempty"`
	// The candidate's token ID value.
	TokenID int32 `json:"tokenId,omitempty"`
}

// Candidates with top log probabilities at each decoding step.
type LogprobsResultTopCandidates struct {
	// Sorted by log probability in descending order.
	Candidates []*LogprobsResultCandidate `json:"candidates,omitempty"`
}

// Logprobs Result
type LogprobsResult struct {
	// Length = total number of decoding steps. The chosen candidates may or may not be
	// in top_candidates.
	ChosenCandidates []*LogprobsResultCandidate `json:"chosenCandidates,omitempty"`
	// Length = total number of decoding steps.
	TopCandidates []*LogprobsResultTopCandidates `json:"topCandidates,omitempty"`
}

// Safety rating corresponding to the generated content.
type SafetyRating struct {
	// Output only. Indicates whether the content was filtered out because of this rating.
	Blocked bool `json:"blocked,omitempty"`
	// Output only. Harm category.
	Category HarmCategory `json:"category,omitempty"`
	// Output only. Harm probability levels in the content.
	Probability HarmProbability `json:"probability,omitempty"`
	// Output only. Harm probability score.
	ProbabilityScore float32 `json:"probabilityScore,omitempty"`
	// Output only. Harm severity levels in the content.
	Severity HarmSeverity `json:"severity,omitempty"`
	// Output only. Harm severity score.
	SeverityScore float32 `json:"severityScore,omitempty"`
}

// A response candidate generated from the model.
type Candidate struct {
	// Contains the multi-part content of the response.
	Content *Content `json:"content,omitempty"`
	// Source attribution of the generated content.
	CitationMetadata *CitationMetadata `json:"citationMetadata,omitempty"`
	// Describes the reason the model stopped generating tokens.
	FinishMessage string `json:"finishMessage,omitempty"`
	// Number of tokens for this candidate.
	// This field is only available in the Gemini API.
	TokenCount int32 `json:"tokenCount,omitempty"`
	// The reason why the model stopped generating tokens.
	// If empty, the model has not stopped generating the tokens.
	FinishReason FinishReason `json:"finishReason,omitempty"`
	// Output only. Average log probability score of the candidate.
	AvgLogprobs float64 `json:"avgLogprobs,omitempty"`
	// Output only. Metadata specifies sources used to ground generated content.
	GroundingMetadata *GroundingMetadata `json:"groundingMetadata,omitempty"`
	// Output only. Index of the candidate.
	Index int32 `json:"index,omitempty"`
	// Output only. Log-likelihood scores for the response tokens and top tokens
	LogprobsResult *LogprobsResult `json:"logprobsResult,omitempty"`
	// Output only. List of ratings for the safety of a response candidate. There is at
	// most one rating per category.
	SafetyRatings []*SafetyRating `json:"safetyRatings,omitempty"`
}

// Content filter results for a prompt sent in the request.
type GenerateContentResponsePromptFeedback struct {
	// Output only. Blocked reason.
	BlockReason BlockedReason `json:"blockReason,omitempty"`
	// Output only. A readable block reason message.
	BlockReasonMessage string `json:"blockReasonMessage,omitempty"`
	// Output only. Safety ratings.
	SafetyRatings []*SafetyRating `json:"safetyRatings,omitempty"`
}

// Represents token counting info for a single modality.
type ModalityTokenCount struct {
	// The modality associated with this token count.
	Modality MediaModality `json:"modality,omitempty"`
	// Number of tokens.
	TokenCount int32 `json:"tokenCount,omitempty"`
}

// Usage metadata about response(s).
type GenerateContentResponseUsageMetadata struct {
	// Output only. List of modalities of the cached content in the request input.
	CacheTokensDetails []*ModalityTokenCount `json:"cacheTokensDetails,omitempty"`
	// Output only. Number of tokens in the cached part in the input (the cached content).
	CachedContentTokenCount int32 `json:"cachedContentTokenCount,omitempty"`
	// Number of tokens in the response(s). This includes all the generated response candidates.
	CandidatesTokenCount int32 `json:"candidatesTokenCount,omitempty"`
	// Output only. List of modalities that were returned in the response.
	CandidatesTokensDetails []*ModalityTokenCount `json:"candidatesTokensDetails,omitempty"`
	// Number of tokens in the prompt. When cached_content is set, this is still the total
	// effective prompt size meaning this includes the number of tokens in the cached content.
	PromptTokenCount int32 `json:"promptTokenCount,omitempty"`
	// Output only. List of modalities that were processed in the request input.
	PromptTokensDetails []*ModalityTokenCount `json:"promptTokensDetails,omitempty"`
	// Output only. Number of tokens present in thoughts output.
	ThoughtsTokenCount int32 `json:"thoughtsTokenCount,omitempty"`
	// Output only. Number of tokens present in tool-use prompt(s).
	ToolUsePromptTokenCount int32 `json:"toolUsePromptTokenCount,omitempty"`
	// Output only. List of modalities that were processed for tool-use request inputs.
	ToolUsePromptTokensDetails []*ModalityTokenCount `json:"toolUsePromptTokensDetails,omitempty"`
	// Total token count for prompt, response candidates, and tool-use prompts (if present).
	TotalTokenCount int32 `json:"totalTokenCount,omitempty"`
	// Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or
	// Provisioned Throughput quota.
	TrafficType TrafficType `json:"trafficType,omitempty"`
}

// Response message for PredictionService.GenerateContent.
type GenerateContentResponse struct {
	// Response variations returned by the model.
	Candidates []*Candidate `json:"candidates,omitempty"`
	// Timestamp when the request is made to the server.
	CreateTime time.Time `json:"createTime,omitempty"`
	// Identifier for each response.
	ResponseID string `json:"responseId,omitempty"`
	// Output only. The model version used to generate the response.
	ModelVersion string `json:"modelVersion,omitempty"`
	// Output only. Content filter results for a prompt sent in the request. Note: Sent
	// only in the first stream chunk. Only happens when no candidates were generated due
	// to content violations.
	PromptFeedback *GenerateContentResponsePromptFeedback `json:"promptFeedback,omitempty"`
	// Usage metadata about the response(s).
	UsageMetadata *GenerateContentResponseUsageMetadata `json:"usageMetadata,omitempty"`
}

// Text concatenates all the text parts in the GenerateContentResponse.
func (r *GenerateContentResponse) Text() string {
	if len(r.Candidates) == 0 || r.Candidates[0].Content == nil || len(r.Candidates[0].Content.Parts) == 0 {
		return ""
	}

	if len(r.Candidates) > 1 {
		log.Println("Warning: there are multiple candidates in the response, returning text from the first one.")
	}

	var texts []string
	var notTextParts []string
	for _, part := range r.Candidates[0].Content.Parts {
		if part.Text != "" {
			if part.Thought {
				continue
			}
			texts = append(texts, part.Text)
		} else {
			if part.InlineData != nil {
				notTextParts = append(notTextParts, "InlineData")
			}
			if part.CodeExecutionResult != nil {
				notTextParts = append(notTextParts, "CodeExecutionResult")
			}
			if part.ExecutableCode != nil {
				notTextParts = append(notTextParts, "ExecutableCode")
			}
			if part.FileData != nil {
				notTextParts = append(notTextParts, "FileData")
			}
			if part.FunctionCall != nil {
				notTextParts = append(notTextParts, "FunctionCall")
			}
			if part.FunctionResponse != nil {
				notTextParts = append(notTextParts, "FunctionResponse")
			}
		}
	}

	if len(notTextParts) > 0 {
		log.Printf("Warning: there are non-text parts %s in the response, returning concatenation of all text parts. Please refer to the non text parts for a full response from model.\n", strings.Join(notTextParts, ", "))
	}

	if len(texts) == 0 {
		return ""
	}

	return strings.Join(texts, "")
}

// FunctionCalls returns the list of function calls in the GenerateContentResponse.
func (r *GenerateContentResponse) FunctionCalls() []*FunctionCall {
	if len(r.Candidates) == 0 || r.Candidates[0].Content == nil || len(r.Candidates[0].Content.Parts) == 0 {
		return nil
	}

	if len(r.Candidates) > 1 {
		log.Println("Warning: there are multiple candidates in the response, returning function calls from the first one.")
	}

	var functionCalls []*FunctionCall
	for _, part := range r.Candidates[0].Content.Parts {
		if part.FunctionCall != nil {
			functionCalls = append(functionCalls, part.FunctionCall)
		}
	}

	if len(functionCalls) == 0 {
		return nil
	}

	return functionCalls
}

// ExecutableCode returns the executable code in the GenerateContentResponse.
func (r *GenerateContentResponse) ExecutableCode() string {
	if len(r.Candidates) == 0 || r.Candidates[0].Content == nil || len(r.Candidates[0].Content.Parts) == 0 {
		return ""
	}

	if len(r.Candidates) > 1 {
		log.Println("Warning: there are multiple candidates in the response, returning executable code from the first one.")
	}

	for _, part := range r.Candidates[0].Content.Parts {
		if part.ExecutableCode != nil {
			return part.ExecutableCode.Code
		}
	}

	return ""
}

// CodeExecutionResult returns the code execution result in the GenerateContentResponse.
func (r *GenerateContentResponse) CodeExecutionResult() string {
	if len(r.Candidates) == 0 || r.Candidates[0].Content == nil || len(r.Candidates[0].Content.Parts) == 0 {
		return ""
	}

	if len(r.Candidates) > 1 {
		log.Println("Warning: there are multiple candidates in the response, returning code execution result from the first one.")
	}

	for _, part := range r.Candidates[0].Content.Parts {
		if part.CodeExecutionResult != nil {
			return part.CodeExecutionResult.Output
		}
	}

	return ""
}

func (c *GenerateContentResponse) MarshalJSON() ([]byte, error) {
	type Alias GenerateContentResponse
	aux := &struct {
		CreateTime *time.Time `json:"createTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.CreateTime.IsZero() {
		aux.CreateTime = &c.CreateTime
	}

	return json.Marshal(aux)
}

// Optional parameters for the EmbedContent method.
type EmbedContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Type of task for which the embedding will be used.
	TaskType string `json:"taskType,omitempty"`
	// Title for the text. Only applicable when TaskType is
	// `RETRIEVAL_DOCUMENT`.
	Title string `json:"title,omitempty"`
	// Reduced dimension for the output embedding. If set,
	// excessive values in the output embedding are truncated from the end.
	// Supported by newer models since 2024 only. You cannot set this value if
	// using the earlier model (`models/embedding-001`).
	OutputDimensionality *int32 `json:"outputDimensionality,omitempty"`
	// Vertex API only. The MIME type of the input.
	MIMEType string `json:"mimeType,omitempty"`
	// Vertex API only. Whether to silently truncate inputs longer than
	// the max sequence length. If this option is set to false, oversized inputs
	// will lead to an INVALID_ARGUMENT error, similar to other text APIs.
	AutoTruncate bool `json:"autoTruncate,omitempty"`
}

// Statistics of the input text associated with the result of content embedding.
type ContentEmbeddingStatistics struct {
	// Vertex API only. If the input text was truncated due to having
	// a length longer than the allowed maximum input.
	Truncated bool `json:"truncated,omitempty"`
	// Vertex API only. Number of tokens of the input text.
	TokenCount float32 `json:"tokenCount,omitempty"`
}

// The embedding generated from an input content.
type ContentEmbedding struct {
	// A list of floats representing an embedding.
	Values []float32 `json:"values,omitempty"`
	// Vertex API only. Statistics of the input text associated with this
	// embedding.
	Statistics *ContentEmbeddingStatistics `json:"statistics,omitempty"`
}

// Request-level metadata for the Vertex Embed Content API.
type EmbedContentMetadata struct {
	// Vertex API only. The total number of billable characters included
	// in the request.
	BillableCharacterCount int32 `json:"billableCharacterCount,omitempty"`
}

// Response for the embed_content method.
type EmbedContentResponse struct {
	// The embeddings for each request, in the same order as provided in
	// the batch request.
	Embeddings []*ContentEmbedding `json:"embeddings,omitempty"`
	// Vertex API only. Metadata about the request.
	Metadata *EmbedContentMetadata `json:"metadata,omitempty"`
}

// The configuration for generating images. You can find API default values and more
// details at VertexAI: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api.
// GeminiAPI: https://ai.google.dev/gemini-api/docs/imagen#imagen-model
type GenerateImagesConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Cloud Storage URI used to store the generated images.
	OutputGCSURI string `json:"outputGcsUri,omitempty"`
	// Description of what to discourage in the generated images.
	NegativePrompt string `json:"negativePrompt,omitempty"`
	// Number of images to generate.
	// If empty, the system will choose a default value (currently 4).
	NumberOfImages int32 `json:"numberOfImages,omitempty"`
	// Aspect ratio of the generated images.
	AspectRatio string `json:"aspectRatio,omitempty"`
	// Controls how much the model adheres to the text prompt. Large
	// values increase output and prompt alignment, but may compromise image
	// quality.
	GuidanceScale *float32 `json:"guidanceScale,omitempty"`
	// Random seed for image generation. This is not available when
	// ``add_watermark`` is set to true.
	Seed *int32 `json:"seed,omitempty"`
	// Filter level for safety filtering.
	SafetyFilterLevel SafetyFilterLevel `json:"safetyFilterLevel,omitempty"`
	// Allows generation of people by the model.
	PersonGeneration PersonGeneration `json:"personGeneration,omitempty"`
	// Whether to report the safety scores of each generated image and
	// the positive prompt in the response.
	IncludeSafetyAttributes bool `json:"includeSafetyAttributes,omitempty"`
	// Whether to include the Responsible AI filter reason if the image
	// is filtered out of the response.
	IncludeRAIReason bool `json:"includeRaiReason,omitempty"`
	// Language of the text in the prompt.
	Language ImagePromptLanguage `json:"language,omitempty"`
	// MIME type of the generated image.
	OutputMIMEType string `json:"outputMimeType,omitempty"`
	// Compression quality of the generated image (for ``image/jpeg``
	// only).
	OutputCompressionQuality *int32 `json:"outputCompressionQuality,omitempty"`
	// Whether to add a watermark to the generated images.
	AddWatermark bool `json:"addWatermark,omitempty"`
	// Whether to use the prompt rewriting logic.
	EnhancePrompt bool `json:"enhancePrompt,omitempty"`
}

// An image.
type Image struct {
	// The Cloud Storage URI of the image. ``Image`` can contain a value
	// for this field or the ``image_bytes`` field but not both.
	GCSURI string `json:"gcsUri,omitempty"`
	// The image bytes data. ``Image`` can contain a value for this field
	// or the ``gcs_uri`` field but not both.
	ImageBytes []byte `json:"imageBytes,omitempty"`
	// The MIME type of the image.
	MIMEType string `json:"mimeType,omitempty"`
}

// Safety attributes of a GeneratedImage or the user-provided prompt.
type SafetyAttributes struct {
	// List of RAI categories.
	Categories []string `json:"categories,omitempty"`
	// List of scores of each categories.
	Scores []float32 `json:"scores,omitempty"`
	// Internal use only.
	ContentType string `json:"contentType,omitempty"`
}

// An output image.
type GeneratedImage struct {
	// The output image data.
	Image *Image `json:"image,omitempty"`
	// Responsible AI filter reason if the image is filtered out of the
	// response.
	RAIFilteredReason string `json:"raiFilteredReason,omitempty"`
	// Safety attributes of the image. Lists of RAI categories and their
	// scores of each content.
	SafetyAttributes *SafetyAttributes `json:"safetyAttributes,omitempty"`
	// The rewritten prompt used for the image generation if the prompt
	// enhancer is enabled.
	EnhancedPrompt string `json:"enhancedPrompt,omitempty"`
}

// The output images response.
type GenerateImagesResponse struct {
	// List of generated images.
	GeneratedImages []*GeneratedImage `json:"generatedImages,omitempty"`
	// Safety attributes of the positive prompt. Only populated if
	// ``include_safety_attributes`` is set to True.
	PositivePromptSafetyAttributes *SafetyAttributes `json:"positivePromptSafetyAttributes,omitempty"`
}

// Configuration for a Mask reference image.
type MaskReferenceConfig struct {
	// Prompts the model to generate a mask instead of you needing to
	// provide one (unless MASK_MODE_USER_PROVIDED is used).
	MaskMode MaskReferenceMode `json:"maskMode,omitempty"`
	// A list of up to 5 class IDs to use for semantic segmentation.
	// Automatically creates an image mask based on specific objects.
	SegmentationClasses []int32 `json:"segmentationClasses,omitempty"`
	// Dilation percentage of the mask provided.
	// Float between 0 and 1.
	MaskDilation *float32 `json:"maskDilation,omitempty"`
}

// Configuration for a Control reference image.
type ControlReferenceConfig struct {
	// The type of control reference image to use.
	ControlType ControlReferenceType `json:"controlType,omitempty"`
	// Defaults to False. When set to True, the control image will be
	// computed by the model based on the control type. When set to False,
	// the control image must be provided by the user.
	EnableControlImageComputation bool `json:"enableControlImageComputation,omitempty"`
}

// Configuration for a Style reference image.
type StyleReferenceConfig struct {
	// A text description of the style to use for the generated image.
	StyleDescription string `json:"styleDescription,omitempty"`
}

// Configuration for a Subject reference image.
type SubjectReferenceConfig struct {
	// The subject type of a subject reference image.
	SubjectType SubjectReferenceType `json:"subjectType,omitempty"`
	// Subject description for the image.
	SubjectDescription string `json:"subjectDescription,omitempty"`
}

// referenceImageAPI represents a Reference image that is sent to API.
type referenceImageAPI struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	ReferenceType string `json:"referenceType,omitempty"`
	// Configuration for the mask reference image.
	MaskImageConfig *MaskReferenceConfig `json:"maskImageConfig,omitempty"`
	// Configuration for the control reference image.
	ControlImageConfig *ControlReferenceConfig `json:"controlImageConfig,omitempty"`
	// Configuration for the style reference image.
	StyleImageConfig *StyleReferenceConfig `json:"styleImageConfig,omitempty"`
	// Configuration for the subject reference image.
	SubjectImageConfig *SubjectReferenceConfig `json:"subjectImageConfig,omitempty"`
}

func (r *referenceImageAPI) referenceImageAPI() *referenceImageAPI {
	return r
}

// ReferenceImage is an interface that represents a generic reference image.
//
// You can create instances that implement this interface using the following
// constructor functions:
//   - NewRawReferenceImage
//   - NewMaskReferenceImage
//   - NewControlReferenceImage
//   - NewStyleReferenceImage
//   - NewSubjectReferenceImage
//   - ...
type ReferenceImage interface {
	referenceImageAPI() *referenceImageAPI
}

// NewRawReferenceImage creates a new RawReferenceImage.
func NewRawReferenceImage(referenceImage *Image, referenceID int32) *RawReferenceImage {
	return &RawReferenceImage{
		ReferenceImage: referenceImage,
		ReferenceID:    referenceID,
		referenceType:  "REFERENCE_TYPE_RAW",
	}
}

// NewMaskReferenceImage creates a new MaskReferenceImage.
func NewMaskReferenceImage(referenceImage *Image, referenceID int32, config *MaskReferenceConfig) *MaskReferenceImage {
	return &MaskReferenceImage{
		ReferenceImage: referenceImage,
		ReferenceID:    referenceID,
		Config:         config,
		referenceType:  "REFERENCE_TYPE_MASK",
	}
}

// NewControlReferenceImage creates a new ControlReferenceImage.
func NewControlReferenceImage(referenceImage *Image, referenceID int32, config *ControlReferenceConfig) *ControlReferenceImage {
	return &ControlReferenceImage{
		ReferenceImage: referenceImage,
		ReferenceID:    referenceID,
		Config:         config,
		referenceType:  "REFERENCE_TYPE_CONTROL",
	}
}

// NewStyleReferenceImage creates a new ControlReferenceImage.
func NewStyleReferenceImage(referenceImage *Image, referenceID int32, config *StyleReferenceConfig) *StyleReferenceImage {
	return &StyleReferenceImage{
		ReferenceImage: referenceImage,
		ReferenceID:    referenceID,
		Config:         config,
		referenceType:  "REFERENCE_TYPE_STYLE",
	}
}

// NewSubjectReferenceImage creates a new SubjectReferenceImage.
func NewSubjectReferenceImage(referenceImage *Image, referenceID int32, config *SubjectReferenceConfig) *SubjectReferenceImage {
	return &SubjectReferenceImage{
		ReferenceImage: referenceImage,
		ReferenceID:    referenceID,
		Config:         config,
		referenceType:  "REFERENCE_TYPE_SUBJECT",
	}
}

// Configuration for editing an image.
type EditImageConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Cloud Storage URI used to store the generated images.
	OutputGCSURI string `json:"outputGcsUri,omitempty"`
	// Description of what to discourage in the generated images.
	NegativePrompt string `json:"negativePrompt,omitempty"`
	// Number of images to generate.
	// If empty, the system will choose a default value (currently 4).
	NumberOfImages int32 `json:"numberOfImages,omitempty"`
	// Aspect ratio of the generated images.
	AspectRatio string `json:"aspectRatio,omitempty"`
	// Controls how much the model adheres to the text prompt. Large
	// values increase output and prompt alignment, but may compromise image
	// quality.
	GuidanceScale *float32 `json:"guidanceScale,omitempty"`
	// Random seed for image generation. This is not available when
	// ``add_watermark`` is set to true.
	Seed *int32 `json:"seed,omitempty"`
	// Filter level for safety filtering.
	SafetyFilterLevel SafetyFilterLevel `json:"safetyFilterLevel,omitempty"`
	// Allows generation of people by the model.
	PersonGeneration PersonGeneration `json:"personGeneration,omitempty"`
	// Whether to report the safety scores of each generated image and
	// the positive prompt in the response.
	IncludeSafetyAttributes bool `json:"includeSafetyAttributes,omitempty"`
	// Whether to include the Responsible AI filter reason if the image
	// is filtered out of the response.
	IncludeRAIReason bool `json:"includeRaiReason,omitempty"`
	// Language of the text in the prompt.
	Language ImagePromptLanguage `json:"language,omitempty"`
	// MIME type of the generated image.
	OutputMIMEType string `json:"outputMimeType,omitempty"`
	// Compression quality of the generated image (for ``image/jpeg``
	// only).
	OutputCompressionQuality *int32 `json:"outputCompressionQuality,omitempty"`
	// Describes the editing mode for the request.
	EditMode EditMode `json:"editMode,omitempty"`
	// The number of sampling steps. A higher value has better image
	// quality, while a lower value has better latency.
	BaseSteps *int32 `json:"baseSteps,omitempty"`
}

// Response for the request to edit an image.
type EditImageResponse struct {
	// Generated images.
	GeneratedImages []*GeneratedImage `json:"generatedImages,omitempty"`
}

// API config for UpscaleImage with fields not exposed to users.
// These fields require default values sent to the API which are not intended
// to be modifiable or exposed to users in the SDK method.
type upscaleImageAPIConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Whether to include a reason for filtered-out images in the
	// response.
	IncludeRAIReason bool `json:"includeRaiReason,omitempty"`
	// The image format that the output should be saved as.
	OutputMIMEType string `json:"outputMimeType,omitempty"`
	// The level of compression if the ``output_mime_type`` is
	// ``image/jpeg``.
	OutputCompressionQuality *int32 `json:"outputCompressionQuality,omitempty"`

	NumberOfImages int32 `json:"numberOfImages,omitempty"`

	Mode string `json:"mode,omitempty"`
}

type UpscaleImageResponse struct {
	// Generated images.
	GeneratedImages []*GeneratedImage `json:"generatedImages,omitempty"`
}

// Optional parameters for models.get method.
type GetModelConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// An endpoint where models are deployed.
type Endpoint struct {
	// Resource name of the endpoint.
	Name string `json:"name,omitempty"`
	// ID of the model that's deployed to the endpoint.
	DeployedModelID string `json:"deployedModelId,omitempty"`
}

// A tuned machine learning model.
type TunedModelInfo struct {
	// ID of the base model that you want to tune.
	BaseModel string `json:"baseModel,omitempty"`
	// Date and time when the base model was created.
	CreateTime time.Time `json:"createTime,omitempty"`
	// Date and time when the base model was last updated.
	UpdateTime time.Time `json:"updateTime,omitempty"`
}

func (c *TunedModelInfo) MarshalJSON() ([]byte, error) {
	type Alias TunedModelInfo
	aux := &struct {
		CreateTime *time.Time `json:"createTime,omitempty"`
		UpdateTime *time.Time `json:"updateTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.CreateTime.IsZero() {
		aux.CreateTime = &c.CreateTime
	}
	if !c.UpdateTime.IsZero() {
		aux.UpdateTime = &c.UpdateTime
	}

	return json.Marshal(aux)
}

// A trained machine learning model.
type Model struct {
	// Resource name of the model.
	Name string `json:"name,omitempty"`
	// Display name of the model.
	DisplayName string `json:"displayName,omitempty"`
	// Description of the model.
	Description string `json:"description,omitempty"`
	// Version ID of the model. A new version is committed when a new
	// model version is uploaded or trained under an existing model ID. The
	// version ID is an auto-incrementing decimal number in string
	// representation.
	Version string `json:"version,omitempty"`
	// List of deployed models created from this base model. Note that a
	// model could have been deployed to endpoints in different locations.
	Endpoints []*Endpoint `json:"endpoints,omitempty"`
	// Labels with user-defined metadata to organize your models.
	Labels map[string]string `json:"labels,omitempty"`
	// Information about the tuned model from the base model.
	TunedModelInfo *TunedModelInfo `json:"tunedModelInfo,omitempty"`
	// The maximum number of input tokens that the model can handle.
	InputTokenLimit int32 `json:"inputTokenLimit,omitempty"`
	// The maximum number of output tokens that the model can generate.
	OutputTokenLimit int32 `json:"outputTokenLimit,omitempty"`
	// List of actions that are supported by the model.
	SupportedActions []string `json:"supportedActions,omitempty"`
}

type ListModelsConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// PageSize specifies the maximum number of cached contents to return per API call.
	// If zero, the server will use a default value.
	PageSize int32 `json:"pageSize,omitempty"`
	// PageToken represents a token used for pagination in API responses. It's an opaque
	// string that should be passed to subsequent requests to retrieve the next page of
	// results. An empty PageToken typically indicates that there are no further pages available.
	PageToken string `json:"pageToken,omitempty"`

	Filter string `json:"filter,omitempty"`
	// QueryBase is a boolean flag to control whether to query base models or tuned models.
	// If nil, then SDK will use the default value Ptr(true).
	QueryBase *bool `json:"queryBase,omitempty"`
}

type ListModelsResponse struct {
	NextPageToken string `json:"nextPageToken,omitempty"`

	Models []*Model `json:"models,omitempty"`
}

type UpdateModelConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`

	DisplayName string `json:"displayName,omitempty"`

	Description string `json:"description,omitempty"`
}

type DeleteModelConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

type DeleteModelResponse struct {
}

// Generation config. You can find API default values and more details at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#generationconfig
// and https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters.
type GenerationConfig struct {
	// Optional. If enabled, audio timestamp will be included in the request to the model.
	AudioTimestamp bool `json:"audioTimestamp,omitempty"`
	// Optional. Number of candidates to generate. If empty, the system will choose a default
	// value (currently 1).
	CandidateCount int32 `json:"candidateCount,omitempty"`
	// Optional. Frequency penalties.
	FrequencyPenalty *float32 `json:"frequencyPenalty,omitempty"`
	// Optional. Logit probabilities.
	Logprobs *int32 `json:"logprobs,omitempty"`
	// Optional. The maximum number of output tokens to generate per message. If empty,
	// API will use a default value. The default value varies by model.
	MaxOutputTokens int32 `json:"maxOutputTokens,omitempty"`
	// Optional. If specified, the media resolution specified will be used.
	MediaResolution MediaResolution `json:"mediaResolution,omitempty"`
	// Optional. Positive penalties.
	PresencePenalty *float32 `json:"presencePenalty,omitempty"`
	// Optional. If true, export the logprobs results in response.
	ResponseLogprobs bool `json:"responseLogprobs,omitempty"`
	// Optional. Output response mimetype of the generated candidate text. Supported mimetype:
	// - `text/plain`: (default) Text output. - `application/json`: JSON response in the
	// candidates. The model needs to be prompted to output the appropriate response type,
	// otherwise the behavior is undefined. This is a preview feature.
	ResponseMIMEType string `json:"responseMimeType,omitempty"`
	// Optional. The `Schema` object allows the definition of input and output data types.
	// These types can be objects, but also primitives and arrays. Represents a select subset
	// of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If
	// set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`:
	// Schema for JSON response.
	ResponseSchema *Schema `json:"responseSchema,omitempty"`
	// Optional. Routing configuration.
	RoutingConfig *GenerationConfigRoutingConfig `json:"routingConfig,omitempty"`
	// Optional. Seed.
	Seed *int32 `json:"seed,omitempty"`
	// Optional. Stop sequences.
	StopSequences []string `json:"stopSequences,omitempty"`
	// Optional. Controls the randomness of predictions.
	Temperature *float32 `json:"temperature,omitempty"`
	// Optional. If specified, top-k sampling will be used.
	TopK *float32 `json:"topK,omitempty"`
	// Optional. If specified, nucleus sampling will be used.
	TopP *float32 `json:"topP,omitempty"`
}

// Config for the count_tokens method.
type CountTokensConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Instructions for the model to steer it toward better performance.
	SystemInstruction *Content `json:"systemInstruction,omitempty"`
	// Code that enables the system to interact with external systems to
	// perform an action outside of the knowledge and scope of the model.
	Tools []*Tool `json:"tools,omitempty"`
	// Configuration that the model uses to generate the response. Not
	// supported by the Gemini Developer API.
	GenerationConfig *GenerationConfig `json:"generationConfig,omitempty"`
}

// Response for counting tokens.
type CountTokensResponse struct {
	// Total number of tokens.
	TotalTokens int32 `json:"totalTokens,omitempty"`
	// Number of tokens in the cached part of the prompt (the cached content). This field
	// is only available in the Gemini API.
	CachedContentTokenCount int32 `json:"cachedContentTokenCount,omitempty"`
}

// Optional parameters for computing tokens.
type ComputeTokensConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Tokens info with a list of tokens and the corresponding list of token ids.
type TokensInfo struct {
	// Optional. Optional fields for the role from the corresponding Content.
	Role string `json:"role,omitempty"`
	// A list of token IDs from the input.
	TokenIDs []int64 `json:"tokenIds,omitempty"`
	// A list of tokens from the input.
	Tokens [][]byte `json:"tokens,omitempty"`
}

func (ti *TokensInfo) UnmarshalJSON(data []byte) error {
	type Alias TokensInfo
	aux := struct {
		TokenIDs []string `json:"tokenIds,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(ti),
	}
	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	// Convert the string value to int64
	if aux.TokenIDs != nil {
		tokenIDs := []int64{}
		for _, tokenID := range aux.TokenIDs {
			tokenIDInt, err := strconv.ParseInt(tokenID, 10, 64)
			if err != nil {
				return err
			}
			tokenIDs = append(tokenIDs, tokenIDInt)
		}
		ti.TokenIDs = tokenIDs
	}
	return nil
}

func (ti *TokensInfo) MarshalJSON() ([]byte, error) {
	type Alias TokensInfo
	aux := struct {
		TokenIDs []string `json:"tokenIds,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(ti),
	}

	if ti.TokenIDs != nil {
		for _, tokenID := range ti.TokenIDs {
			aux.TokenIDs = append(aux.TokenIDs, strconv.FormatInt(tokenID, 10))
		}
	}

	return json.Marshal(aux)
}

// Response for computing tokens.
type ComputeTokensResponse struct {
	// Lists of tokens info from the input. A ComputeTokensRequest could have multiple instances
	// with a prompt in each instance. We also need to return lists of tokens info for the
	// request with multiple instances.
	TokensInfo []*TokensInfo `json:"tokensInfo,omitempty"`
}

// You can find API default values and more details at VertexAI: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation.
type GenerateVideosConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Number of output videos. If empty, the system will choose a default value.
	NumberOfVideos int32 `json:"numberOfVideos,omitempty"`
	// The GCS bucket where to save the generated videos.
	OutputGCSURI string `json:"outputGcsUri,omitempty"`
	// Frames per second for video generation.
	FPS *int32 `json:"fps,omitempty"`
	// Duration of the clip for video generation in seconds.
	DurationSeconds *int32 `json:"durationSeconds,omitempty"`
	// The RNG seed. If RNG seed is exactly same for each request with unchanged inputs,
	// the prediction results will be consistent. Otherwise, a random RNG seed will be used
	// each time to produce a different result.
	Seed *int32 `json:"seed,omitempty"`
	// The aspect ratio for the generated video. 16:9 (landscape) and 9:16 (portrait) are
	// supported.
	AspectRatio string `json:"aspectRatio,omitempty"`
	// The resolution for the generated video. 1280x720, 1920x1080 are supported.
	Resolution string `json:"resolution,omitempty"`
	// Whether allow to generate person videos, and restrict to specific ages. Supported
	// values are: dont_allow, allow_adult.
	PersonGeneration string `json:"personGeneration,omitempty"`
	// The pubsub topic where to publish the video generation progress.
	PubsubTopic string `json:"pubsubTopic,omitempty"`
	// Optional field in addition to the text content. Negative prompts can be explicitly
	// stated here to help generate the video.
	NegativePrompt string `json:"negativePrompt,omitempty"`
	// Whether to use the prompt rewriting logic.
	EnhancePrompt bool `json:"enhancePrompt,omitempty"`
}

// A generated video.
type Video struct {
	// Path to another storage.
	URI string `json:"uri,omitempty"`
	// Video bytes.
	VideoBytes []byte `json:"videoBytes,omitempty"`
	// Video encoding, for example "video/mp4".
	MIMEType string `json:"mimeType,omitempty"`
}

func (v *Video) uri() string {
	return v.URI
}

func (v *Video) setVideoBytes(b []byte) bool {
	v.VideoBytes = b
	return true
}

// A generated video.
type GeneratedVideo struct {
	// The output video
	Video *Video `json:"video,omitempty"`
}

func (v *GeneratedVideo) uri() string {
	return v.Video.uri()
}

func (v *GeneratedVideo) setVideoBytes(b []byte) bool {
	v.Video.setVideoBytes(b)
	return true
}

// Response with generated videos.
type GenerateVideosResponse struct {
	// List of the generated videos
	GeneratedVideos []*GeneratedVideo `json:"generatedVideos,omitempty"`
	// Returns if any videos were filtered due to RAI policies.
	RAIMediaFilteredCount int32 `json:"raiMediaFilteredCount,omitempty"`
	// Returns RAI failure reasons if any.
	RAIMediaFilteredReasons []string `json:"raiMediaFilteredReasons,omitempty"`
}

// A video generation operation.
type GenerateVideosOperation struct {
	// The server-assigned name, which is only unique within the same service that originally
	// returns it. If you use the default HTTP mapping, the `name` should be a resource
	// name ending with `operations/{unique_id}`.
	Name string `json:"name,omitempty"`
	// Service-specific metadata associated with the operation. It typically contains progress
	// information and common metadata such as create time. Some services might not provide
	// such metadata. Any method that returns a long-running operation should document the
	// metadata type, if any.
	Metadata map[string]any `json:"metadata,omitempty"`
	// If the value is `false`, it means the operation is still in progress. If `true`,
	// the operation is completed, and either `error` or `response` is available.
	Done bool `json:"done,omitempty"`
	// The error result of the operation in case of failure or cancellation.
	Error map[string]any `json:"error,omitempty"`
	// The generated videos.
	Response *GenerateVideosResponse `json:"response,omitempty"`
}

// Optional configuration for cached content creation.
type CreateCachedContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// The TTL for this resource. The expiration time is computed: now + TTL.
	TTL time.Duration `json:"ttl,omitempty"`
	// Timestamp of when this resource is considered expired.
	ExpireTime time.Time `json:"expireTime,omitempty"`
	// The user-generated meaningful display name of the cached content.
	DisplayName string `json:"displayName,omitempty"`
	// The content to cache.
	Contents []*Content `json:"contents,omitempty"`
	// Developer set system instruction.
	SystemInstruction *Content `json:"systemInstruction,omitempty"`
	// A list of `Tools` the model may use to generate the next response.
	Tools []*Tool `json:"tools,omitempty"`
	// Configuration for the tools to use. This config is shared for all tools.
	ToolConfig *ToolConfig `json:"toolConfig,omitempty"`
}

func (c *CreateCachedContentConfig) MarshalJSON() ([]byte, error) {
	type Alias CreateCachedContentConfig
	aux := &struct {
		ExpireTime *time.Time `json:"expireTime,omitempty"`
		TTL        string     `json:"ttl,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.ExpireTime.IsZero() {
		aux.ExpireTime = &c.ExpireTime
	}
	if c.TTL != 0 {
		aux.TTL = fmt.Sprintf("%.0fs", c.TTL.Seconds())
	}

	return json.Marshal(aux)
}

func (c *CreateCachedContentConfig) UnmarshalJSON(data []byte) error {
	type Alias CreateCachedContentConfig
	aux := &struct {
		TTL string `json:"ttl,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.TTL != "" {
		d, err := time.ParseDuration(aux.TTL)
		if err != nil {
			return err
		}
		c.TTL = d
	}

	return nil
}

// Metadata on the usage of the cached content.
type CachedContentUsageMetadata struct {
	// Duration of audio in seconds.
	AudioDurationSeconds int32 `json:"audioDurationSeconds,omitempty"`
	// Number of images.
	ImageCount int32 `json:"imageCount,omitempty"`
	// Number of text characters.
	TextCount int32 `json:"textCount,omitempty"`
	// Total number of tokens that the cached content consumes.
	TotalTokenCount int32 `json:"totalTokenCount,omitempty"`
	// Duration of video in seconds.
	VideoDurationSeconds int32 `json:"videoDurationSeconds,omitempty"`
}

// A resource used in LLM queries for users to explicitly specify what to cache.
type CachedContent struct {
	// The server-generated resource name of the cached content.
	Name string `json:"name,omitempty"`
	// The user-generated meaningful display name of the cached content.
	DisplayName string `json:"displayName,omitempty"`
	// The name of the publisher model to use for cached content.
	Model string `json:"model,omitempty"`
	// Creation time of the cache entry.
	CreateTime time.Time `json:"createTime,omitempty"`
	// When the cache entry was last updated in UTC time.
	UpdateTime time.Time `json:"updateTime,omitempty"`
	// Expiration time of the cached content.
	ExpireTime time.Time `json:"expireTime,omitempty"`
	// Metadata on the usage of the cached content.
	UsageMetadata *CachedContentUsageMetadata `json:"usageMetadata,omitempty"`
}

func (c *CachedContent) MarshalJSON() ([]byte, error) {
	type Alias CachedContent
	aux := &struct {
		ExpireTime *time.Time `json:"expireTime,omitempty"`
		CreateTime *time.Time `json:"createTime,omitempty"`
		UpdateTime *time.Time `json:"updateTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.ExpireTime.IsZero() {
		aux.ExpireTime = &c.ExpireTime
	}
	if !c.CreateTime.IsZero() {
		aux.CreateTime = &c.CreateTime
	}
	if !c.UpdateTime.IsZero() {
		aux.UpdateTime = &c.UpdateTime
	}

	return json.Marshal(aux)
}

// Optional parameters for caches.get method.
type GetCachedContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Optional parameters for caches.delete method.
type DeleteCachedContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Empty response for caches.delete method.
type DeleteCachedContentResponse struct {
}

// Optional parameters for caches.update method.
type UpdateCachedContentConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// The TTL for this resource. The expiration time is computed: now + TTL.
	TTL time.Duration `json:"ttl,omitempty"`
	// Timestamp of when this resource is considered expired.
	ExpireTime time.Time `json:"expireTime,omitempty"`
}

func (c *UpdateCachedContentConfig) MarshalJSON() ([]byte, error) {
	type Alias UpdateCachedContentConfig
	aux := &struct {
		ExpireTime *time.Time `json:"expireTime,omitempty"`
		TTL        string     `json:"ttl,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if !c.ExpireTime.IsZero() {
		aux.ExpireTime = &c.ExpireTime
	}
	if c.TTL != 0 {
		aux.TTL = fmt.Sprintf("%.0fs", c.TTL.Seconds())
	}

	return json.Marshal(aux)
}

func (c *UpdateCachedContentConfig) UnmarshalJSON(data []byte) error {
	type Alias UpdateCachedContentConfig
	aux := &struct {
		TTL string `json:"ttl,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.TTL != "" {
		d, err := time.ParseDuration(aux.TTL)
		if err != nil {
			return err
		}
		c.TTL = d
	}

	return nil
}

// Config for caches.list method.
type ListCachedContentsConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// PageSize specifies the maximum number of cached contents to return per API call.
	// If zero, the server will use a default value.
	PageSize int32 `json:"pageSize,omitempty"`
	// PageToken represents a token used for pagination in API responses. It's an opaque
	// string that should be passed to subsequent requests to retrieve the next page of
	// results. An empty PageToken typically indicates that there are no further pages available.
	PageToken string `json:"pageToken,omitempty"`
}

type ListCachedContentsResponse struct {
	NextPageToken string `json:"nextPageToken,omitempty"`
	// List of cached contents.
	CachedContents []*CachedContent `json:"cachedContents,omitempty"`
}

// Used to override the default configuration.
type ListFilesConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// PageSize specifies the maximum number of cached contents to return per API call.
	// If zero, the server will use a default value.
	PageSize int32 `json:"pageSize,omitempty"`
	// PageToken represents a token used for pagination in API responses. It's an opaque
	// string that should be passed to subsequent requests to retrieve the next page of
	// results. An empty PageToken typically indicates that there are no further pages available.
	PageToken string `json:"pageToken,omitempty"`
}

// Status of a File that uses a common error model.
type FileStatus struct {
	// A list of messages that carry the error details. There is a common set of message
	// types for APIs to use.
	Details []map[string]any `json:"details,omitempty"`
	// A list of messages that carry the error details. There is a common set of message
	// types for APIs to use.
	Message string `json:"message,omitempty"`
	// The status code. 0 for OK, 1 for CANCELLED
	Code *int32 `json:"code,omitempty"`
}

// A file uploaded to the API.
type File struct {
	// The `File` resource name. The ID (name excluding the "files/" prefix) can contain
	// up to 40 characters that are lowercase alphanumeric or dashes (-). The ID cannot
	// start or end with a dash. If the name is empty on create, a unique name will be generated.
	// Example: `files/123-456`
	Name string `json:"name,omitempty"`
	// Optional. The human-readable display name for the `File`. The display name must be
	// no more than 512 characters in length, including spaces. Example: 'Welcome Image'
	DisplayName string `json:"displayName,omitempty"`
	// Output only. MIME type of the file.
	MIMEType string `json:"mimeType,omitempty"`
	// Output only. Size of the file in bytes.
	SizeBytes *int64 `json:"sizeBytes,omitempty"`
	// Output only. The timestamp of when the `File` was created.
	CreateTime time.Time `json:"createTime,omitempty"`
	// Output only. The timestamp of when the `File` will be deleted. Only set if the `File`
	// is scheduled to expire.
	ExpirationTime time.Time `json:"expirationTime,omitempty"`
	// Output only. The timestamp of when the `File` was last updated.
	UpdateTime time.Time `json:"updateTime,omitempty"`
	// Output only. SHA-256 hash of the uploaded bytes. The hash value is encoded in base64
	// format.
	Sha256Hash string `json:"sha256Hash,omitempty"`
	// Output only. The URI of the `File`.
	URI string `json:"uri,omitempty"`
	// Output only. The URI of the `File`, only set for downloadable (generated) files.
	DownloadURI string `json:"downloadUri,omitempty"`
	// Output only. Processing state of the File.
	State FileState `json:"state,omitempty"`
	// Output only. The source of the `File`.
	Source FileSource `json:"source,omitempty"`
	// Output only. Metadata for a video.
	VideoMetadata map[string]any `json:"videoMetadata,omitempty"`
	// Output only. Error status if File processing failed.
	Error *FileStatus `json:"error,omitempty"`
}

// DownloadURI represents a resource that can be downloaded.
//
// It is used to abstract the different types of resources that can be downloaded,
// such as files or videos
//
// You can create instances that implement this interface using the following
// constructor functions:
//   - NewDownloadURIFromFile
//   - NewDownloadURIFromVideo
//   - NewDownloadURIFromGeneratedVideo
//   - ...
type DownloadURI interface {
	uri() string
	setVideoBytes([]byte) bool
}

// NewDownloadURIFromFile creates a DownloadURI from a [File].
func NewDownloadURIFromFile(f *File) DownloadURI {
	return f
}

// NewDownloadURIFromVideo creates a DownloadURI from a [Video].
func NewDownloadURIFromVideo(v *Video) DownloadURI {
	return v
}

// NewDownloadURIFromVideo creates a DownloadURI from a [GeneratedVideo].
func NewDownloadURIFromGeneratedVideo(v *GeneratedVideo) DownloadURI {
	return v
}

func (f *File) uri() string {
	return f.DownloadURI
}

func (f *File) setVideoBytes(b []byte) bool {
	// File does not support setting video bytes.
	return false
}

func (f *File) UnmarshalJSON(data []byte) error {
	type Alias File
	aux := &struct {
		*Alias
		SizeBytes string `json:"sizeBytes,omitempty"`
	}{
		Alias: (*Alias)(f),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.SizeBytes != "" {
		sizeBytes, err := strconv.ParseInt(aux.SizeBytes, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing SizeBytes: %w", err)
		}
		f.SizeBytes = &sizeBytes
	}

	return nil
}

func (f *File) MarshalJSON() ([]byte, error) {
	type Alias File
	aux := struct {
		*Alias
		SizeBytes      string     `json:"sizeBytes,omitempty"`
		ExpirationTime *time.Time `json:"expirationTime,omitempty"`
		CreateTime     *time.Time `json:"createTime,omitempty"`
		UpdateTime     *time.Time `json:"updateTime,omitempty"`
	}{
		Alias: (*Alias)(f),
	}

	if f.SizeBytes != nil {
		aux.SizeBytes = strconv.FormatInt(*f.SizeBytes, 10)
	}

	if !f.ExpirationTime.IsZero() {
		aux.ExpirationTime = &f.ExpirationTime
	}
	if !f.CreateTime.IsZero() {
		aux.CreateTime = &f.CreateTime
	}
	if !f.UpdateTime.IsZero() {
		aux.UpdateTime = &f.UpdateTime
	}

	return json.Marshal(aux)
}

// Response for the list files method.
type ListFilesResponse struct {
	// A token to retrieve next page of results.
	NextPageToken string `json:"nextPageToken,omitempty"`
	// The list of files.
	Files []*File `json:"files,omitempty"`
}

// Used to override the default configuration.
type CreateFileConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Response for the create file method.
type CreateFileResponse struct {
	// Used to retain the HTTP headers in the request
	HTTPHeaders http.Header `json:"httpHeaders,omitempty"`
}

// Used to override the default configuration.
type GetFileConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Used to override the default configuration.
type DeleteFileConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Response for the delete file method.
type DeleteFileResponse struct {
}

type GetOperationConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

type FetchPredictOperationConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

type testTableItem struct {
	// The name of the test. This is used to derive the replay id.
	Name string `json:"name,omitempty"`
	// The parameters to the test. Use pydantic models.
	Parameters map[string]any `json:"parameters,omitempty"`
	// Expects an exception for MLDev matching the string.
	ExceptionIfMLDev string `json:"exceptionIfMldev,omitempty"`
	// Expects an exception for Vertex matching the string.
	ExceptionIfVertex string `json:"exceptionIfVertex,omitempty"`
	// Use if you don't want to use the default replay ID which is derived from the test
	// name.
	OverrideReplayID string `json:"overrideReplayId,omitempty"`
	// True if the parameters contain an unsupported union type. This test will be skipped
	// for languages that do not support the union type.
	HasUnion bool `json:"hasUnion,omitempty"`
	// When set to a reason string, this test will be skipped in the API mode. Use this
	// flag for tests that can not be reproduced with the real API. E.g. a test that deletes
	// a resource.
	SkipInAPIMode string `json:"skipInApiMode,omitempty"`
	// Keys to ignore when comparing the request and response. This is useful for tests
	// that are not deterministic.
	IgnoreKeys []string `json:"ignoreKeys,omitempty"`
}

type testTableFile struct {
	Comment string `json:"comment,omitempty"`

	TestMethod string `json:"testMethod,omitempty"`

	ParameterNames []string `json:"parameterNames,omitempty"`

	TestTable []*testTableItem `json:"testTable,omitempty"`
}

// Represents a single request in a replay.
type replayRequest struct {
	Method string `json:"method,omitempty"`

	URL string `json:"url,omitempty"`

	Headers map[string]string `json:"headers,omitempty"`

	BodySegments []map[string]any `json:"bodySegments,omitempty"`
}

// Represents a single response in a replay.
type replayResponse struct {
	StatusCode int32 `json:"statusCode,omitempty"`

	Headers map[string]string `json:"headers,omitempty"`

	BodySegments []map[string]any `json:"bodySegments,omitempty"`

	SDKResponseSegments []map[string]any `json:"sdkResponseSegments,omitempty"`
}

// Represents a single interaction, request and response in a replay.
type replayInteraction struct {
	Request *replayRequest `json:"request,omitempty"`

	Response *replayResponse `json:"response,omitempty"`
}

// Represents a recorded session.
type replayFile struct {
	ReplayID string `json:"replayId,omitempty"`

	Interactions []*replayInteraction `json:"interactions,omitempty"`
}

// Used to override the default configuration.
type UploadFileConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// The name of the file in the destination (e.g., 'files/sample-image'. If not provided
	// one will be generated.
	Name string `json:"name,omitempty"`
	// mime_type: The MIME type of the file. If not provided, it will be inferred from the
	// file extension.
	MIMEType string `json:"mimeType,omitempty"`
	// Optional display name of the file.
	DisplayName string `json:"displayName,omitempty"`
}

// Used to override the default configuration.
type DownloadFileConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
}

// Configuration for upscaling an image.
// For more information on this configuration, refer to
// the `Imagen API reference documentation
// <https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/imagen-api>`_.
type UpscaleImageConfig struct {
	// Used to override HTTP request options.
	HTTPOptions *HTTPOptions `json:"httpOptions,omitempty"`
	// Whether to include a reason for filtered-out images in the
	// response.
	IncludeRAIReason bool `json:"includeRaiReason,omitempty"`
	// The image format that the output should be saved as.
	OutputMIMEType string `json:"outputMimeType,omitempty"`
	// The level of compression if the OutputMIMEType is image/jpeg.
	OutputCompressionQuality *int32 `json:"outputCompressionQuality,omitempty"`
}

// A raw reference image.
// A raw reference image represents the base image to edit, provided by the user.
// It can optionally be provided in addition to a mask reference image or
// a style reference image.
type RawReferenceImage struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	referenceType string
}

func (r *RawReferenceImage) referenceImageAPI() *referenceImageAPI {
	return &referenceImageAPI{
		ReferenceImage: r.ReferenceImage,
		ReferenceID:    r.ReferenceID,
		ReferenceType:  "REFERENCE_TYPE_RAW",
	}
}

// A mask reference image. This encapsulates either a mask image provided by the user
// and configs for the user provided mask, or only config parameters for the model to
// generate a mask. A mask image is an image whose non-zero values indicate where to
// edit the base image. If the user provides a mask image, the mask must be in the same
// dimensions as the raw image.
type MaskReferenceImage struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	referenceType string
	// Configuration for the mask reference image.
	Config *MaskReferenceConfig `json:"config,omitempty"`
}

func (r *MaskReferenceImage) referenceImageAPI() *referenceImageAPI {
	return &referenceImageAPI{
		ReferenceImage:  r.ReferenceImage,
		ReferenceID:     r.ReferenceID,
		ReferenceType:   "REFERENCE_TYPE_MASK",
		MaskImageConfig: r.Config,
	}
}

// A control image is an image that represents a sketch image of areas for the model
// to fill in based on the prompt. Its image is either a control image provided by the
// user, or a regular image which the backend will use to generate a control image of.
// In the case of the latter, the EnableControlImageComputation field in the config
// should be set to true.
type ControlReferenceImage struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	referenceType string
	// Configuration for the control reference image.
	Config *ControlReferenceConfig `json:"config,omitempty"`
}

func (r *ControlReferenceImage) referenceImageAPI() *referenceImageAPI {
	return &referenceImageAPI{
		ReferenceImage:     r.ReferenceImage,
		ReferenceID:        r.ReferenceID,
		ReferenceType:      "REFERENCE_TYPE_CONTROL",
		ControlImageConfig: r.Config,
	}
}

// A style reference image.
// This encapsulates a style reference image provided by the user, and
// additionally optional config parameters for the style reference image.
// A raw reference image can also be provided as a destination for the style to
// be applied to.
type StyleReferenceImage struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	referenceType string
	// Configuration for the style reference image.
	Config *StyleReferenceConfig `json:"config,omitempty"`
}

func (r *StyleReferenceImage) referenceImageAPI() *referenceImageAPI {
	return &referenceImageAPI{
		ReferenceImage:   r.ReferenceImage,
		ReferenceID:      r.ReferenceID,
		ReferenceType:    "REFERENCE_TYPE_CONTROL",
		StyleImageConfig: r.Config,
	}
}

// A subject reference image.
// This encapsulates a subject reference image provided by the user, and
// additionally optional config parameters for the subject reference image.
// A raw reference image can also be provided as a destination for the subject to
// be applied to.
type SubjectReferenceImage struct {
	// The reference image for the editing operation.
	ReferenceImage *Image `json:"referenceImage,omitempty"`
	// The ID of the reference image.
	ReferenceID int32 `json:"referenceId,omitempty"`
	// The type of the reference image. Only set by the SDK.
	referenceType string
	// Configuration for the subject reference image.
	Config *SubjectReferenceConfig `json:"config,omitempty"`
}

func (r *SubjectReferenceImage) referenceImageAPI() *referenceImageAPI {
	return &referenceImageAPI{
		ReferenceImage:     r.ReferenceImage,
		ReferenceID:        r.ReferenceID,
		ReferenceType:      "REFERENCE_TYPE_CONTROL",
		SubjectImageConfig: r.Config,
	}
}

// Sent in response to a `LiveGenerateContentSetup` message from the client.
type LiveServerSetupComplete struct {
}

// Audio transcription in Server Conent.
type Transcription struct {
	// Transcription text.
	Text string `json:"text,omitempty"`
	// The bool indicates the end of the transcription.
	Finished bool `json:"finished,omitempty"`
}

// Incremental server update generated by the model in response to client messages.
// Content is generated as quickly as possible, and not in real time. Clients
// may choose to buffer and play it out in real time.
type LiveServerContent struct {
	// The content that the model has generated as part of the current conversation with
	// the user.
	ModelTurn *Content `json:"modelTurn,omitempty"`
	// If true, indicates that the model is done generating. Generation will only start
	// in response to additional client messages. Can be set alongside `content`, indicating
	// that the `content` is the last in the turn.
	TurnComplete bool `json:"turnComplete,omitempty"`
	// If true, indicates that a client message has interrupted current model generation.
	// If the client is playing out the content in realtime, this is a good signal to stop
	// and empty the current queue.
	Interrupted bool `json:"interrupted,omitempty"`
	// If true, indicates that the model is done generating. When model is
	// interrupted while generating there will be no generation_complete message
	// in interrupted turn, it will go through interrupted > turn_complete.
	// When model assumes realtime playback there will be delay between
	// generation_complete and turn_complete that is caused by model
	// waiting for playback to finish. If true, indicates that the model
	// has finished generating all content. This is a signal to the client
	// that it can stop sending messages.
	GenerationComplete bool `json:"generationComplete,omitempty"`
	// Input transcription. The transcription is independent to the model
	// turn which means it doesn’t imply any ordering between transcription and
	// model turn.
	InputTranscription *Transcription `json:"inputTranscription,omitempty"`
	// Output transcription. The transcription is independent to the model
	// turn which means it doesn’t imply any ordering between transcription and
	// model turn.
	OutputTranscription *Transcription `json:"outputTranscription,omitempty"`
}

// Request for the client to execute the `function_calls` and return the responses with
// the matching `id`s.
type LiveServerToolCall struct {
	// The function call to be executed.
	FunctionCalls []*FunctionCall `json:"functionCalls,omitempty"`
}

// Notification for the client that a previously issued `ToolCallMessage` with the specified
// `id`s should have been not executed and should be cancelled.
// If there were side-effects to those tool calls, clients may attempt to undo
// the tool calls. This message occurs only in cases where the clients interrupt
// server turns.
type LiveServerToolCallCancellation struct {
	// The IDs of the tool calls to be cancelled.
	IDs []string `json:"ids,omitempty"`
}

// Usage metadata about response(s).
type UsageMetadata struct {
	// Number of tokens in the prompt. When `cached_content` is set, this is still the total
	// effective prompt size meaning this includes the number of tokens in the cached content.
	PromptTokenCount int32 `json:"promptTokenCount,omitempty"`
	// Number of tokens in the cached part of the prompt (the cached content).
	CachedContentTokenCount int32 `json:"cachedContentTokenCount,omitempty"`
	// Total number of tokens across all the generated response candidates.
	ResponseTokenCount int32 `json:"responseTokenCount,omitempty"`
	// Number of tokens present in tool-use prompt(s).
	ToolUsePromptTokenCount int32 `json:"toolUsePromptTokenCount,omitempty"`
	// Number of tokens of thoughts for thinking models.
	ThoughtsTokenCount int32 `json:"thoughtsTokenCount,omitempty"`
	// Total token count for prompt, response candidates, and tool-use prompts(if present).
	TotalTokenCount int32 `json:"totalTokenCount,omitempty"`
	// List of modalities that were processed in the request input.
	PromptTokensDetails []*ModalityTokenCount `json:"promptTokensDetails,omitempty"`
	// List of modalities that were processed in the cache input.
	CacheTokensDetails []*ModalityTokenCount `json:"cacheTokensDetails,omitempty"`
	// List of modalities that were returned in the response.
	ResponseTokensDetails []*ModalityTokenCount `json:"responseTokensDetails,omitempty"`
	// List of modalities that were processed in the tool-use prompt.
	ToolUsePromptTokensDetails []*ModalityTokenCount `json:"toolUsePromptTokensDetails,omitempty"`
	// Traffic type. This shows whether a request consumes Pay-As-You-Go
	// or Provisioned Throughput quota.
	TrafficType TrafficType `json:"trafficType,omitempty"`
}

// Server will not be able to service client soon.
type LiveServerGoAway struct {
	// The remaining time before the connection will be terminated as ABORTED. The minimal
	// time returned here is specified differently together with the rate limits for a given
	// model.
	TimeLeft time.Duration `json:"timeLeft,omitempty"`
}

func (c *LiveServerGoAway) MarshalJSON() ([]byte, error) {
	type Alias LiveServerGoAway
	aux := &struct {
		TimeLeft string `json:"timeLeft,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if c.TimeLeft != 0 {
		aux.TimeLeft = fmt.Sprintf("%.0fs", c.TimeLeft.Seconds())
	}

	return json.Marshal(aux)
}

func (c *LiveServerGoAway) UnmarshalJSON(data []byte) error {
	type Alias LiveServerGoAway
	aux := &struct {
		TimeLeft string `json:"timeLeft,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(c),
	}

	if aux.TimeLeft != "" {
		d, err := time.ParseDuration(aux.TimeLeft)
		if err != nil {
			return err
		}
		c.TimeLeft = d
	}

	return nil
}

// Update of the session resumption state.
// Only sent if `session_resumption` was set in the connection config.
type LiveServerSessionResumptionUpdate struct {
	// New handle that represents state that can be resumed. Empty if `resumable`=false.
	NewHandle string `json:"newHandle,omitempty"`
	// True if session can be resumed at this point. It might be not possible to resume
	// session at some points. In that case we send update empty new_handle and resumable=false.
	// Example of such case could be model executing function calls or just generating.
	// Resuming session (using previous session token) in such state will result in some
	// data loss.
	Resumable bool `json:"resumable,omitempty"`
	// Index of last message sent by client that is included in state represented by this
	// SessionResumptionToken. Only sent when `SessionResumptionConfig.transparent` is set.
	// Presence of this index allows users to transparently reconnect and avoid issue of
	// losing some part of realtime audio input/video. If client wishes to temporarily disconnect
	// (for example as result of receiving GoAway) they can do it without losing state by
	// buffering messages sent since last `SessionResmumptionTokenUpdate`. This field will
	// enable them to limit buffering (avoid keeping all requests in RAM).
	// Note: This should not be used for when resuming a session at some time later -- in
	// those cases partial audio and video frames arelikely not needed.
	LastConsumedClientMessageIndex int64 `json:"lastConsumedClientMessageIndex,omitempty"`
}

func (s *LiveServerSessionResumptionUpdate) UnmarshalJSON(data []byte) error {
	type Alias LiveServerSessionResumptionUpdate
	aux := &struct {
		LastConsumedClientMessageIndex string `json:"lastConsumedClientMessageIndex,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(s),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.LastConsumedClientMessageIndex != "" {
		LastConsumedClientMessageIndex, err := strconv.ParseInt(aux.LastConsumedClientMessageIndex, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing LastConsumedClientMessageIndex: %w", err)
		}
		s.LastConsumedClientMessageIndex = LastConsumedClientMessageIndex
	}

	return nil
}

func (s *LiveServerSessionResumptionUpdate) MarshalJSON() ([]byte, error) {
	type Alias LiveServerSessionResumptionUpdate
	aux := struct {
		LastConsumedClientMessageIndex string `json:"maxLength,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(s),
	}

	if s.LastConsumedClientMessageIndex != 0 {
		aux.LastConsumedClientMessageIndex = strconv.FormatInt(s.LastConsumedClientMessageIndex, 10)
	}
	return json.Marshal(aux)
}

// Response message for API call.
type LiveServerMessage struct {
	// Sent in response to a `LiveClientSetup` message from the client.
	SetupComplete *LiveServerSetupComplete `json:"setupComplete,omitempty"`
	// Content generated by the model in response to client messages.
	ServerContent *LiveServerContent `json:"serverContent,omitempty"`
	// Request for the client to execute the `function_calls` and return the responses with
	// the matching `id`s.
	ToolCall *LiveServerToolCall `json:"toolCall,omitempty"`
	// Notification for the client that a previously issued `ToolCallMessage` with the specified
	// `id`s should have been not executed and should be cancelled.
	ToolCallCancellation *LiveServerToolCallCancellation `json:"toolCallCancellation,omitempty"`
	// Usage metadata about model response(s).
	UsageMetadata *UsageMetadata `json:"usageMetadata,omitempty"`
	// Server will disconnect soon.
	GoAway *LiveServerGoAway `json:"goAway,omitempty"`
	// Update of the session resumption state.
	SessionResumptionUpdate *LiveServerSessionResumptionUpdate `json:"sessionResumptionUpdate,omitempty"`
}

// Configures automatic detection of activity.
type AutomaticActivityDetection struct {
	// If enabled, detected voice and text input count as activity. If disabled, the client
	// must send activity signals.
	Disabled bool `json:"disabled,omitempty"`
	// Determines how likely speech is to be detected.
	StartOfSpeechSensitivity StartSensitivity `json:"startOfSpeechSensitivity,omitempty"`
	// Determines how likely detected speech is ended.
	EndOfSpeechSensitivity EndSensitivity `json:"endOfSpeechSensitivity,omitempty"`
	// The required duration of detected speech before start-of-speech is committed. The
	// lower this value the more sensitive the start-of-speech detection is and the shorter
	// speech can be recognized. However, this also increases the probability of false positives.
	PrefixPaddingMs *int32 `json:"prefixPaddingMs,omitempty"`
	// The required duration of detected non-speech (e.g. silence) before end-of-speech
	// is committed. The larger this value, the longer speech gaps can be without interrupting
	// the user's activity but this will increase the model's latency.
	SilenceDurationMs *int32 `json:"silenceDurationMs,omitempty"`
}

// Marks the end of user activity.
// This can only be sent if automatic (i.e. server-side) activity detection is
// disabled.
type RealtimeInputConfig struct {
	// If not set, automatic activity detection is enabled by default. If automatic voice
	// detection is disabled, the client must send activity signals.
	AutomaticActivityDetection *AutomaticActivityDetection `json:"automaticActivityDetection,omitempty"`
	// Defines what effect activity has.
	ActivityHandling ActivityHandling `json:"activityHandling,omitempty"`
	// Defines which input is included in the user's turn.
	TurnCoverage TurnCoverage `json:"turnCoverage,omitempty"`
}

// Configuration of session resumption mechanism.
// Included in `LiveConnectConfig.session_resumption`. If included server
// will send `LiveServerSessionResumptionUpdate` messages.
type SessionResumptionConfig struct {
	// Session resumption handle of previous session (session to restore).
	// If not present new session will be started.
	Handle string `json:"handle,omitempty"`
	// If set the server will send `last_consumed_client_message_index` in the `session_resumption_update`
	// messages to allow for transparent reconnections.
	Transparent bool `json:"transparent,omitempty"`
}

// Context window will be truncated by keeping only suffix of it.
// Context window will always be cut at start of USER role turn. System
// instructions and `BidiGenerateContentSetup.prefix_turns` will not be
// subject to the sliding window mechanism, they will always stay at the
// beginning of context window.
type SlidingWindow struct {
	// Session reduction target -- how many tokens we should keep. Window shortening operation
	// has some latency costs, so we should avoid running it on every turn. Should be <
	// trigger_tokens. If not set, trigger_tokens/2 is assumed.
	TargetTokens *int64 `json:"targetTokens,omitempty"`
}

func (s *SlidingWindow) UnmarshalJSON(data []byte) error {
	type Alias SlidingWindow
	aux := &struct {
		*Alias
		TargetTokens string `json:"targetTokens,omitempty"`
	}{
		Alias: (*Alias)(s),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.TargetTokens != "" {
		targetTokens, err := strconv.ParseInt(aux.TargetTokens, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing TargetTokens: %w", err)
		}
		s.TargetTokens = &targetTokens
	}

	return nil
}

func (s *SlidingWindow) MarshalJSON() ([]byte, error) {
	type Alias SlidingWindow
	aux := &struct {
		*Alias
		TargetTokens string `json:"targetTokens,omitempty"`
	}{
		Alias: (*Alias)(s),
	}

	if s.TargetTokens != nil {
		aux.TargetTokens = strconv.FormatInt(*s.TargetTokens, 10)
	}

	return json.Marshal(aux)
}

// Enables context window compression -- mechanism managing model context window so
// it does not exceed given length.
type ContextWindowCompressionConfig struct {
	// Number of tokens (before running turn) that triggers context window compression mechanism.
	TriggerTokens *int64 `json:"triggerTokens,omitempty"`
	// Sliding window compression mechanism.
	SlidingWindow *SlidingWindow `json:"slidingWindow,omitempty"`
}

func (c *ContextWindowCompressionConfig) UnmarshalJSON(data []byte) error {
	type Alias ContextWindowCompressionConfig
	aux := &struct {
		*Alias
		TriggerTokens string `json:"triggerTokens,omitempty"`
	}{
		Alias: (*Alias)(c),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if aux.TriggerTokens != "" {
		triggerTokens, err := strconv.ParseInt(aux.TriggerTokens, 10, 64)
		if err != nil {
			return fmt.Errorf("error parsing TriggerTokens: %w", err)
		}
		c.TriggerTokens = &triggerTokens
	}

	return nil
}

func (c *ContextWindowCompressionConfig) MarshalJSON() ([]byte, error) {
	type Alias ContextWindowCompressionConfig
	aux := &struct {
		*Alias
		TriggerTokens string `json:"triggerTokens,omitempty"`
	}{
		Alias: (*Alias)(c),
	}

	if c.TriggerTokens != nil {
		aux.TriggerTokens = strconv.FormatInt(*c.TriggerTokens, 10)
	}

	return json.Marshal(aux)
}

// The audio transcription configuration in Setup.
type AudioTranscriptionConfig struct {
}

// Message contains configuration that will apply for the duration of the streaming
// session.
type LiveClientSetup struct {
	// The fully qualified name of the publisher model or tuned model endpoint to
	// use.
	Model string `json:"model,omitempty"`
	// The generation configuration for the session.
	// Note: only a subset of fields are supported.
	GenerationConfig *GenerationConfig `json:"generationConfig,omitempty"`
	// The user provided system instructions for the model.
	// Note: only text should be used in parts and content in each part will be
	// in a separate paragraph.
	SystemInstruction *Content `json:"systemInstruction,omitempty"`
	// A list of `Tools` the model may use to generate the next response.
	// A `Tool` is a piece of code that enables the system to interact with
	// external systems to perform an action, or set of actions, outside of
	// knowledge and scope of the model.
	Tools []*Tool `json:"tools,omitempty"`
	// Configures the realtime input behavior in BidiGenerateContent.
	RealtimeInputConfig *RealtimeInputConfig `json:"realtimeInputConfig,omitempty"`
	// Configures session resumption mechanism.
	// If included server will send SessionResumptionUpdate messages.
	SessionResumption *SessionResumptionConfig `json:"sessionResumption,omitempty"`
	// Configures context window compression mechanism.
	// If included, server will compress context window to fit into given length.
	ContextWindowCompression *ContextWindowCompressionConfig `json:"contextWindowCompression,omitempty"`
	// The transcription of the input aligns with the input audio language.
	InputAudioTranscription *AudioTranscriptionConfig `json:"inputAudioTranscription,omitempty"`
	// The transcription of the output aligns with the language code
	// specified for the output audio.
	OutputAudioTranscription *AudioTranscriptionConfig `json:"outputAudioTranscription,omitempty"`
}

// Incremental update of the current conversation delivered from the client.
// All the content here will unconditionally be appended to the conversation
// history and used as part of the prompt to the model to generate content.
// A message here will interrupt any current model generation.
type LiveClientContent struct {
	// The content appended to the current conversation with the model.
	// For single-turn queries, this is a single instance. For multi-turn
	// queries, this is a repeated field that contains conversation history and
	// latest request.
	Turns []*Content `json:"turns,omitempty"`
	// If true, indicates that the server content generation should start with
	// the currently accumulated prompt. Otherwise, the server will await
	// additional messages before starting generation.
	TurnComplete bool `json:"turnComplete,omitempty"`
}

// Marks the start of user activity.
// This can only be sent if automatic (i.e. server-side) activity detection is
// disabled.
type ActivityStart struct {
}

// Marks the end of user activity.
// This can only be sent if automatic (i.e. server-side) activity detection is
// disabled.
type ActivityEnd struct {
}

// User input that is sent in real time.
// This is different from `LiveClientContent` in a few ways:
//   - Can be sent continuously without interruption to model generation.
//   - If there is a need to mix data interleaved across the
//     `LiveClientContent` and the `LiveClientRealtimeInput`, server attempts to
//     optimize for best response, but there are no guarantees.
//   - End of turn is not explicitly specified, but is rather derived from user
//     activity (for example, end of speech).
//   - Even before the end of turn, the data is processed incrementally
//     to optimize for a fast start of the response from the model.
//   - Is always assumed to be the user's input (cannot be used to populate
//     conversation history).
type LiveClientRealtimeInput struct {
	// Inlined bytes data for media input.
	MediaChunks []*Blob `json:"mediaChunks,omitempty"`
	// Marks the start of user activity.
	ActivityStart *ActivityStart `json:"activityStart,omitempty"`
	// Marks the end of user activity.
	ActivityEnd *ActivityEnd `json:"activityEnd,omitempty"`
}

// Client generated response to a `ToolCall` received from the server.
// Individual `FunctionResponse` objects are matched to the respective
// `FunctionCall` objects by the `id` field.
// Note that in the unary and server-streaming GenerateContent APIs function
// calling happens by exchanging the `Content` parts, while in the bidi
// GenerateContent APIs function calling happens over this dedicated set of
// messages.
type LiveClientToolResponse struct {
	// The response to the function calls.
	FunctionResponses []*FunctionResponse `json:"functionResponses,omitempty"`
}

// Messages sent by the client in the API call.
type LiveClientMessage struct {
	// Message to be sent by the system when connecting to the API. SDK users should not
	// send this message.
	Setup *LiveClientSetup `json:"setup,omitempty"`
	// Incremental update of the current conversation delivered from the client.
	ClientContent *LiveClientContent `json:"clientContent,omitempty"`
	// User input that is sent in real time.
	RealtimeInput *LiveClientRealtimeInput `json:"realtimeInput,omitempty"`
	// Response to a `ToolCallMessage` received from the server.
	ToolResponse *LiveClientToolResponse `json:"toolResponse,omitempty"`
}

// Session config for the API connection.
type LiveConnectConfig struct {
	// The requested modalities of the response. Represents the set of
	// modalities that the model can return. Defaults to AUDIO if not specified.
	ResponseModalities []Modality `json:"responseModalities,omitempty"`
	// Value that controls the degree of randomness in token selection.
	// Lower temperatures are good for prompts that require a less open-ended or
	// creative response, while higher temperatures can lead to more diverse or
	// creative results.
	Temperature *float32 `json:"temperature,omitempty"`
	// Tokens are selected from the most to least probable until the sum
	// of their probabilities equals this value. Use a lower value for less
	// random responses and a higher value for more random responses.
	TopP *float32 `json:"topP,omitempty"`
	// For each token selection step, the ``top_k`` tokens with the
	// highest probabilities are sampled. Then tokens are further filtered based
	// on ``top_p`` with the final token selected using temperature sampling. Use
	// a lower number for less random responses and a higher number for more
	// random responses.
	TopK *float32 `json:"topK,omitempty"`
	// Maximum number of tokens that can be generated in the response.
	// If empty, API will use a default value. The default value varies by model.
	MaxOutputTokens int32 `json:"maxOutputTokens,omitempty"`
	// If specified, the media resolution specified will be used.
	MediaResolution MediaResolution `json:"mediaResolution,omitempty"`
	// When ``seed`` is fixed to a specific number, the model makes a best
	// effort to provide the same response for repeated requests. By default, a
	// random number is used.
	Seed *int32 `json:"seed,omitempty"`
	// The speech generation configuration.
	SpeechConfig *SpeechConfig `json:"speechConfig,omitempty"`
	// The user provided system instructions for the model.
	// Note: only text should be used in parts and content in each part will be
	// in a separate paragraph.
	SystemInstruction *Content `json:"systemInstruction,omitempty"`
	// A list of `Tools` the model may use to generate the next response.
	// A `Tool` is a piece of code that enables the system to interact with
	// external systems to perform an action, or set of actions, outside of
	// knowledge and scope of the model.
	Tools []*Tool `json:"tools,omitempty"`
	// Configures session resumption mechanism.
	// If included the server will send SessionResumptionUpdate messages.
	SessionResumption *SessionResumptionConfig `json:"sessionResumption,omitempty"`
	// The transcription of the input aligns with the input audio language.
	InputAudioTranscription *AudioTranscriptionConfig `json:"inputAudioTranscription,omitempty"`
	// The transcription of the output aligns with the language code
	// specified for the output audio.
	OutputAudioTranscription *AudioTranscriptionConfig `json:"outputAudioTranscription,omitempty"`
	// Configures the realtime input behavior in BidiGenerateContent.
	RealtimeInputConfig *RealtimeInputConfig `json:"realtimeInputConfig,omitempty"`
	// Configures context window compression mechanism.
	// If included, server will compress context window to fit into given length.
	ContextWindowCompression *ContextWindowCompressionConfig `json:"contextWindowCompression,omitempty"`
}

// Parameters for sending client content to the live API.
type LiveSendClientContentParameters struct {
	// Client content to send to the session.
	Turns []*Content `json:"turns,omitempty"`
	// If true, indicates that the server content generation should start with
	// the currently accumulated prompt. Otherwise, the server will await
	// additional messages before starting generation. If nil, then SDK will use the default
	// value Ptr(true).
	TurnComplete *bool `json:"turnComplete,omitempty"`
}

func (p LiveSendClientContentParameters) toLiveClientMessage() *LiveClientMessage {
	if p.TurnComplete == nil {
		p.TurnComplete = Ptr(true)
	}
	return &LiveClientMessage{
		ClientContent: &LiveClientContent{Turns: p.Turns, TurnComplete: *p.TurnComplete},
	}
}

// Parameters for sending realtime input to the live API.
type LiveSendRealtimeInputParameters struct {
	// Realtime input to send to the session.
	Media *Blob `json:"media,omitempty"`
	// The realtime audio input stream.
	Audio *Blob `json:"audio,omitempty"`
	// Indicates that the audio stream has ended, e.g. because the microphone was
	// turned off.
	// This should only be sent when automatic activity detection is enabled
	// (which is the default).
	// The client can reopen the stream by sending an audio message.
	AudioStreamEnd bool `json:"audioStreamEnd,omitempty"`
	// The realtime video input stream.
	Video *Blob `json:"video,omitempty"`
	// The realtime text input stream.
	Text string `json:"text,omitempty"`
	// Marks the start of user activity.
	ActivityStart *ActivityStart `json:"activityStart,omitempty"`
	// Marks the end of user activity.
	ActivityEnd *ActivityEnd `json:"activityEnd,omitempty"`
}

// Parameters for sending tool responses to the live API.
type LiveSendToolResponseParameters struct {
	// Tool responses to send to the session.
	FunctionResponses []*FunctionResponse `json:"functionResponses,omitempty"`
}

func (p LiveSendToolResponseParameters) toLiveClientMessage() *LiveClientMessage {
	return &LiveClientMessage{
		ToolResponse: &LiveClientToolResponse{FunctionResponses: p.FunctionResponses},
	}
}
